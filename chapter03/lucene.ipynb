{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: this Java notebook requires Ganymede \n",
    "* Ganymede (JShell in Jupyter): [Installation and documentation](https://github.com/allen-ball/ganymede)\n",
    "* We need additional libraries for lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pom\n",
    "dependencies:\n",
    "- org.apache.lucene:lucene-core:LATEST\n",
    "- org.apache.lucene:lucene-analyzers-common:LATEST\n",
    "- org.apache.lucene:lucene-queryparser:LATEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common imports (java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.BufferedReader;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.io.Reader;\n",
    "import java.io.StringReader;\n",
    "\n",
    "import java.util.Arrays;\n",
    "import java.util.ArrayList;\n",
    "import java.util.HashMap;\n",
    "import java.util.Map;\n",
    "import java.util.regex.Pattern;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common imports (lucene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.lucene.analysis.Analyzer;\n",
    "import org.apache.lucene.analysis.TokenStream;  \n",
    "import org.apache.lucene.analysis.Tokenizer;\n",
    "import org.apache.lucene.analysis.core.LowerCaseFilter;\n",
    "import org.apache.lucene.analysis.en.EnglishAnalyzer;\n",
    "import org.apache.lucene.analysis.en.EnglishPossessiveFilter;\n",
    "import org.apache.lucene.analysis.en.KStemFilter;\n",
    "import org.apache.lucene.analysis.standard.StandardAnalyzer;\n",
    "import org.apache.lucene.analysis.standard.StandardFilter;\n",
    "import org.apache.lucene.analysis.standard.StandardTokenizer;\n",
    "import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n",
    "import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n",
    "import org.apache.lucene.analysis.util.CharArraySet;\n",
    "\n",
    "import org.apache.lucene.util.Version;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's read in the data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1000 documents from datasets/imdb_top_1000.csv\n"
     ]
    }
   ],
   "source": [
    "ArrayList<Map<String, String>> read_collection(String name) {\n",
    "    ArrayList<Map<String, String>> docs = new ArrayList<Map<String, String>>();\n",
    "    String splitter = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\";\n",
    "    \n",
    "    try{\n",
    "        BufferedReader reader = new BufferedReader(new FileReader(name));\n",
    "        String line, keys[] = reader.readLine().split(splitter);\n",
    "\n",
    "        while ((line = reader.readLine()) != null) {\n",
    "            String[] values = line.split(splitter);\n",
    "            Map<String, String> dataMap = new HashMap<>();\n",
    "\n",
    "            for (int i = 0; i < keys.length; i++) {\n",
    "                // dataMap.put(keys[i], values[i]);\n",
    "                switch(keys[i]){\n",
    "                    case \"Series_Title\":\n",
    "                        dataMap.put(\"title\", values[i]);\n",
    "                        break;\n",
    "                    case \"Released_Year\":\n",
    "                        dataMap.put(\"year\", values[i]);\n",
    "                        break;\n",
    "                    case \"Runtime\":\n",
    "                        dataMap.put(\"runtime\", values[i].replace(\" min\", \"\"));\n",
    "                        break;\n",
    "                    case \"Genre\":\n",
    "                        dataMap.put(\"genre\", values[i].replace(\",\",\"\"));\n",
    "                        break;\n",
    "                    case \"IMDB_Rating\":\n",
    "                        dataMap.put(\"rating\", values[i]);\n",
    "                        break;\n",
    "                    case \"Overview\":\n",
    "                        dataMap.put(\"summary\", values[i]);\n",
    "                        break;\n",
    "                    case \"Star1\":\n",
    "                        dataMap.put(\"actors\", values[i]);\n",
    "                        break;\n",
    "                    case \"Star2\":\n",
    "                    case \"Star3\":\n",
    "                    case \"Star4\":\n",
    "                        dataMap.put(\"actors\", dataMap.get(\"actors\") + \" \" + values[i]);\n",
    "                        break;\n",
    "                }\n",
    "            }\n",
    "            docs.add(dataMap);\n",
    "        }\n",
    "    } catch(IOException e) {\n",
    "        e.printStackTrace();\n",
    "    }\n",
    "    System.out.println(\"Read \" + docs.size() + \" documents from \" + name);\n",
    "    return docs;\n",
    "}\n",
    "\n",
    "var collection = read_collection(\"datasets/imdb_top_1000.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with the analyzer of Lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[but, be, with, such, then, for, no, will, not, are, and, their, if, this, on, into, a, or, there, in, that, they, was, is, it, an, the, as, at, these, by, to, of]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text: I think text's values' color goes here; WHAT happens with it? do we see IT again; I went there to be gone with houses\n",
      "\n",
      "         standard: i think text's values color goes here what happens do we see again i went gone houses \n",
      "          english: i think text valu color goe here what happen do we see again i went gone hous \n",
      "english/stopwords: think text valu color goe here what happen with it we see it again went there to be gone with hous \n",
      "      my analyzer: I think text value color go here WHAT happen with it do we see IT again I went there to be gone with house \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "void print_tokens(Analyzer analyzer, String text) {\n",
    "    try {\n",
    "        TokenStream ts = analyzer.tokenStream(\"text\", new StringReader(text));\n",
    "        CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n",
    "\n",
    "        try {\n",
    "            ts.reset();\n",
    "            // Print all tokens until stream is exhausted\n",
    "            while (ts.incrementToken()) \n",
    "                System.out.print(termAtt.toString() + \" \");\n",
    "            ts.end();\n",
    "            System.out.println();\n",
    "        } finally {\n",
    "            ts.close();\n",
    "        }\n",
    "    } catch(IOException e) {\n",
    "        e.printStackTrace();\n",
    "    }    \n",
    "}\n",
    "\n",
    "class MyAnalyzer extends Analyzer {\n",
    "    MyAnalyzer(Version matchVersion) {\n",
    "    }\n",
    "    @Override\n",
    "    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n",
    "        Version matchVersion = Version.LUCENE_CURRENT;\n",
    "        final Tokenizer source = new StandardTokenizer(matchVersion, reader);\n",
    "        TokenStream result = new StandardFilter(matchVersion, source);\n",
    "        result = new EnglishPossessiveFilter(matchVersion, result);\n",
    "        // result = new LowerCaseFilter(matchVersion, result);\n",
    "        result = new KStemFilter(result);\n",
    "        return new TokenStreamComponents(source, result);\n",
    "    }\n",
    "}\n",
    "\n",
    "var text = \"I think text's values' color goes here; WHAT happens with it? do we see IT again; I went there to be gone with houses\";\n",
    "var stopWords = new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(\"i\", \"do\"), false);\n",
    "\n",
    "System.out.println(\"             text: \"+ text);\n",
    "System.out.println();\n",
    "\n",
    "// standard analyzer\n",
    "System.out.print(\"         standard: \");\n",
    "print_tokens(new StandardAnalyzer(Version.LUCENE_CURRENT), text);\n",
    "\n",
    "// english analyzer (with porter stemmer)\n",
    "System.out.print(\"          english: \");\n",
    "print_tokens(new EnglishAnalyzer(Version.LUCENE_CURRENT), text);\n",
    "\n",
    "// english analyzer (with porter stemmer) and new set of stopwords\n",
    "System.out.print(\"english/stopwords: \");\n",
    "print_tokens(new EnglishAnalyzer(Version.LUCENE_CURRENT, stopWords), text);\n",
    "\n",
    "// a custom analyzer, no lower case and kstemmer\n",
    "System.out.print(\"      my analyzer: \");\n",
    "print_tokens(new MyAnalyzer(Version.LUCENE_CURRENT), text);\n",
    "\n",
    "EnglishAnalyzer.getDefaultStopSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an index (in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REJECTED ERRONEOUS\n",
      "\n",
      "\n",
      "print(xchart)\n",
      "cannot find symbol\n",
      "  symbol:   method print(org.knowm.xchart.XYChart)\n",
      "  location: class \n"
     ]
    }
   ],
   "source": [
    "import org.knowm.xchart.XYChart;\n",
    "import org.knowm.xchart.XYChartBuilder;\n",
    "\n",
    "var xchart = new XYChartBuilder().title(\"Trig\").build();\n",
    "\n",
    "xchart.addSeries(\"sin\", x, sinx);\n",
    "xchart.addSeries(\"cos\", x, cosx);\n",
    "\n",
    "print(xchart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ganymede 2.1.1 (Java 18)",
   "language": "java",
   "name": "ganymede-2.1.1-java-18"
  },
  "language_info": {
   "file_extension": ".java",
   "mimetype": "text/x-java",
   "name": "java",
   "version": "11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
