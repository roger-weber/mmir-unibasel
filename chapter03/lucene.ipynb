{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: this Java notebook requires Ganymede \n",
    "* Ganymede (Java kernel for Jupyter): [Installation and documentation](https://github.com/allen-ball/ganymede)\n",
    "* We need additional libraries for lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pom\n",
    "dependencies:\n",
    "- org.apache.lucene:lucene-core:9.7.0\n",
    "- org.apache.lucene:lucene-analysis-common:9.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common imports (java)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.BufferedReader;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.io.Reader;\n",
    "import java.io.StringReader;\n",
    "\n",
    "import java.util.Arrays;\n",
    "import java.util.ArrayList;\n",
    "import java.util.HashMap;\n",
    "import java.util.Map;\n",
    "import java.util.regex.Pattern;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common imports (lucene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.lucene.analysis.Analyzer;\n",
    "import org.apache.lucene.analysis.FilteringTokenFilter;\n",
    "import org.apache.lucene.analysis.TokenStream;  \n",
    "import org.apache.lucene.analysis.Tokenizer;\n",
    "import org.apache.lucene.analysis.LowerCaseFilter;\n",
    "import org.apache.lucene.analysis.Analyzer.TokenStreamComponents;\n",
    "import org.apache.lucene.analysis.en.EnglishAnalyzer;\n",
    "import org.apache.lucene.analysis.en.EnglishPossessiveFilter;\n",
    "import org.apache.lucene.analysis.en.KStemFilter;\n",
    "import org.apache.lucene.analysis.standard.StandardAnalyzer;\n",
    "import org.apache.lucene.analysis.standard.StandardTokenizer;\n",
    "import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n",
    "import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n",
    "import org.apache.lucene.analysis.CharArraySet;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's read in the data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1000 documents from datasets/imdb_top_1000.csv\n",
      "\n",
      "first document:\n",
      "   summary: Two imprisoned men bond over a number of years, finding solace and eventual redemption through acts of common decency.\n",
      "    actors: Tim Robbins Morgan Freeman Bob Gunton William Sadler\n",
      "      year: 1994\n",
      "     genre: Drama\n",
      "    rating: 9.3\n",
      "   runtime: 142\n",
      "     title: The Shawshank Redemption\n"
     ]
    }
   ],
   "source": [
    "ArrayList<Map<String, String>> read_collection(String name) throws IOException {\n",
    "    ArrayList<Map<String, String>> docs = new ArrayList<Map<String, String>>();\n",
    "    String splitter = \",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\";\n",
    "    BufferedReader reader = new BufferedReader(new FileReader(name));\n",
    "    String line, keys[] = reader.readLine().split(splitter);\n",
    "\n",
    "    while ((line = reader.readLine()) != null) {\n",
    "        String[] values = line.split(splitter);\n",
    "        Map<String, String> dataMap = new HashMap<>();\n",
    "\n",
    "        for (int i = 0; i < keys.length; i++) {\n",
    "            // dataMap.put(keys[i], values[i]);\n",
    "            switch(keys[i]){\n",
    "                case \"Series_Title\":\n",
    "                    dataMap.put(\"title\", values[i]);\n",
    "                    break;\n",
    "                case \"Released_Year\":\n",
    "                    dataMap.put(\"year\", values[i]);\n",
    "                    break;\n",
    "                case \"Runtime\":\n",
    "                    dataMap.put(\"runtime\", values[i].replace(\" min\", \"\"));\n",
    "                    break;\n",
    "                case \"Genre\":\n",
    "                    dataMap.put(\"genre\", values[i].replace(\",\",\"\"));\n",
    "                    break;\n",
    "                case \"IMDB_Rating\":\n",
    "                    dataMap.put(\"rating\", values[i]);\n",
    "                    break;\n",
    "                case \"Overview\":\n",
    "                    dataMap.put(\"summary\", values[i].replace(\"\\\"\", \"\"));\n",
    "                    break;\n",
    "                case \"Star1\":\n",
    "                    dataMap.put(\"actors\", values[i]);\n",
    "                    break;\n",
    "                case \"Star2\":\n",
    "                case \"Star3\":\n",
    "                case \"Star4\":\n",
    "                    dataMap.put(\"actors\", dataMap.get(\"actors\") + \" \" + values[i]);\n",
    "                    break;\n",
    "            }\n",
    "        }\n",
    "        docs.add(dataMap);\n",
    "    }\n",
    "    reader.close();\n",
    "\n",
    "    // print summary\n",
    "    System.out.println(\"Read \" + docs.size() + \" documents from \" + name);\n",
    "    return docs;\n",
    "}\n",
    "\n",
    "var collection = read_collection(\"datasets/imdb_top_1000.csv\");\n",
    "System.out.println(\"\\nfirst document:\");\n",
    "collection.get(0).forEach((key, value) -> System.out.println(String.format(\"%10s: %s\", key, value)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with the analyzer of Lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text: I think text's values' color goes here; WHAT happens with it? do we see IT again; I went there to be gone with houses\n",
      "\n",
      "         standard: i think text's values color goes here what happens with it do we see it again i went there to be gone with houses \n",
      "          english: i think text valu color goe here what happen do we see again i went gone hous \n",
      "english/stopwords: think text valu color goe here what happen with it we see it again went there to be gone with hous \n",
      "      my analyzer: think text value color go here WHAT happen with again went there gone with house \n",
      "\n",
      "stopword list:\n",
      "[but, be, with, such, then, for, no, will, not, are, and, their, if, this, on, into, a, or, there, in, that, they, was, is, it, an, the, as, at, these, by, to, of]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "void print_tokens(Analyzer analyzer, String text) throws IOException {\n",
    "    TokenStream ts = analyzer.tokenStream(\"text\", new StringReader(text));\n",
    "    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n",
    "\n",
    "    for(ts.reset(); ts.incrementToken();) \n",
    "        System.out.print(termAtt.toString() + \" \");\n",
    "    ts.end();\n",
    "    System.out.println();\n",
    "}\n",
    "\n",
    "class MyAnalyzer extends Analyzer {\n",
    "    @Override\n",
    "    protected TokenStreamComponents createComponents(String fieldName) {\n",
    "          final Tokenizer source = new StandardTokenizer();\n",
    "          TokenStream result = new EnglishPossessiveFilter(source);\n",
    "          // result = new LowerCaseFilter(result);\n",
    "          result = new FilteringTokenFilter(result) {\n",
    "              private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n",
    "              @Override\n",
    "              protected boolean accept() throws IOException {\n",
    "                  return termAtt.length() > 3;\n",
    "              }\n",
    "          };\n",
    "          result = new KStemFilter(result);\n",
    "          return new TokenStreamComponents(source, result);\n",
    "    }\n",
    "}\n",
    "\n",
    "var text = \"I think text's values' color goes here; WHAT happens with it? do we see IT again; I went there to be gone with houses\";\n",
    "var stopWords = new CharArraySet(Arrays.asList(\"i\", \"do\"), false);\n",
    "\n",
    "System.out.println(\"             text: \"+ text);\n",
    "System.out.println();\n",
    "\n",
    "// standard analyzer\n",
    "System.out.print(\"         standard: \");\n",
    "print_tokens(new StandardAnalyzer(), text);\n",
    "\n",
    "// english analyzer (with porter stemmer)\n",
    "System.out.print(\"          english: \");\n",
    "print_tokens(new EnglishAnalyzer(), text);\n",
    "\n",
    "// english analyzer (with porter stemmer) and new set of stopwords\n",
    "System.out.print(\"english/stopwords: \");\n",
    "print_tokens(new EnglishAnalyzer(stopWords), text);\n",
    "\n",
    "// a custom analyzer, no lower case and kstemmer\n",
    "System.out.print(\"      my analyzer: \");\n",
    "print_tokens(new MyAnalyzer(), text);\n",
    "\n",
    "// print standard stop word list\n",
    "System.out.println(\"\\nenglish stopword list:\");\n",
    "System.out.println(EnglishAnalyzer.getDefaultStopSet());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an index (in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "REJECTED ERRONEOUS\n",
      "\n",
      "\n",
      "print(xchart)\n",
      "cannot find symbol\n",
      "  symbol:   method print(org.knowm.xchart.XYChart)\n",
      "  location: class \n"
     ]
    }
   ],
   "source": [
    "import org.knowm.xchart.XYChart;\n",
    "import org.knowm.xchart.XYChartBuilder;\n",
    "\n",
    "var xchart = new XYChartBuilder().title(\"Trig\").build();\n",
    "\n",
    "xchart.addSeries(\"sin\", x, sinx);\n",
    "xchart.addSeries(\"cos\", x, cosx);\n",
    "\n",
    "print(xchart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ganymede 2.1.1 (Java 17)",
   "language": "java",
   "name": "ganymede-2.1.1-java-17"
  },
  "language_info": {
   "file_extension": ".java",
   "mimetype": "text/x-java",
   "name": "java",
   "version": "11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
