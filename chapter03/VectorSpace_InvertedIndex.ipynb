{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space retrieval with inverted files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer & Set of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': 1, 'simple': 1, 'test': 1}\n",
      "{'a': 1, 'for': 1, 'function': 1, 'is': 1, 'simple': 1, 'test': 1, 'this': 2}\n"
     ]
    }
   ],
   "source": [
    "from utils import analyzer\n",
    "\n",
    "print(analyzer.bag_of_words(\"this is a simple test for this function\", remove_stopwords = True))\n",
    "print(analyzer.bag_of_words(\"this is a simple test for this function\", remove_stopwords = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopKList class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush\n",
    "from typing import Callable\n",
    "\n",
    "class TopKList:\n",
    "    \"\"\"\n",
    "        Maintains a list of top-k documents. Initializer accepts\n",
    "        a list of tuples (term, weight) to provide information about\n",
    "        weights used by retrieval model. Implements the iter() interface.\n",
    "        Takes an optional predicate(doc_id: int) function to filter documents\n",
    "        before returning them. \n",
    "    \"\"\"\n",
    "    def __init__(self, k: int, term_weights: list[tuple[str,float]] = None, predicate: Callable[[int], bool] = None):\n",
    "        self.docs_heap = []\n",
    "        self.k = k\n",
    "        self.predicate = predicate\n",
    "        self.results = []\n",
    "        if term_weights:\n",
    "            self.term_weights = term_weights\n",
    "            self.terms = [term for term, _ in self.term_weights]\n",
    "            self.weights = dict(self.term_weights)\n",
    "    \n",
    "    def add(self, doc_id: int, score: float):\n",
    "        heappush(self.docs_heap, (-score, doc_id, {'id': doc_id, 'score': score}))\n",
    "        # optional (infrequent) pruning if heap grows too large\n",
    "\n",
    "    def __iter__(self):\n",
    "        # do we already have the results?\n",
    "        for entry in self.results:\n",
    "            yield entry\n",
    "        # produce more results (if necessary and available)\n",
    "        rank = len(self.results)\n",
    "        while rank < self.k and len(self.docs_heap) > 0:\n",
    "            entry = heappop(self.docs_heap)[2]\n",
    "            if self.predicate == None or self.predicate(entry['id']):\n",
    "                rank += 1\n",
    "                entry['rank'] = rank\n",
    "                self.results.append(entry)\n",
    "                yield entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF implementations and BM25 parameters\n",
    "BM25 parameters are typically `k=1.2` and `b=0.75`, while `adl` must be set from the collection. If we leave `adl=None`, the term normalization does not take document length into account (which is ok if documents in the collection have about equal length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "BM25 = { 'k': 1.2, 'b': 0.75, 'adl': None }\n",
    "\n",
    "def idf(doc_freq: int, num_docs: int) -> float:\n",
    "    return math.log((num_docs + 1) / (doc_freq + 1))\n",
    "\n",
    "def idf_bm25(doc_freq: int, num_docs: int) -> float:\n",
    "    return math.log((num_docs - doc_freq + 0.5) / (doc_freq + 0.5))\n",
    "    \n",
    "def idf_bm25_pos(doc_freq: int, num_docs: int) -> float:\n",
    "    return math.log((num_docs + 1) / (doc_freq + 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF normalization functions\n",
    "We apply document normalization at index building time. We also use normalized query vectors so that similarity becomes a simple dot product between document and query vector. The function below performs term normalization for documents given a bag-of-word and a vocabulary. The vocabulary maps a term to a dictionary that holds the idf values for the dot-product and cosine measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def normalize_doc_vector(vector: dict[str, int], vocabulary: dict[str, dict], measure: str) -> dict[str, float]:\n",
    "    # dot-product: multiply each term's tf by its idf\n",
    "    if measure == 'dot':\n",
    "        return {term: tf * vocabulary[term]['idf'] for term,tf in vector.items()}\n",
    "\n",
    "    # cosine-measure: multiply each term's tf by its idf and divide by total vector length\n",
    "    if measure == 'cosine':\n",
    "        norm = sum([(tf * vocabulary[term]['idf']) ** 2 for term, tf in vector.items()]) ** 0.5\n",
    "        return {term: tf * vocabulary[term]['idf'] / norm for term, tf in vector.items()}\n",
    "\n",
    "    # bm25: normalize with bm25 formula with document length\n",
    "    if measure == 'bm25' and BM25['adl']:\n",
    "        doc_len = sum(vector.values())\n",
    "        return {term: tf * (BM25['k'] + 1) / (tf + BM25['k'] * (1 - BM25['b'] + BM25['b'] * doc_len / BM25['adl']))  for term, tf in vector.items()}\n",
    "\n",
    "    # bm25: normalize with bm25 formula without document length\n",
    "    if measure in ['bm25', 'bm25-nolen', 'bm25-pos']:\n",
    "        return {term: tf * (BM25['k'] + 1) / (tf + BM25['k'])  for term, tf in vector.items()}\n",
    "\n",
    "    raise ValueError('Unknown normalization measure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Base Retriever Class\n",
    "* `n_docs: int`: number of documents added to index\n",
    "* `documents dict[int, dict{'id', 'vector', 'norm-vector'}]`: collection of documents as dictionary with doc_id as key. Each document is a dictionary with the properties from the dataset and additional properties for the retrieval\n",
    "  - `id` hold the document id as generated when loading the document; corresponds to the key in documents\n",
    "  - `vector` holds the term freqeuncies as dictionary (key=term, value=term frequency)\n",
    "  - `norm-vector` normalized vector for the selected measure\n",
    "* `vocabulary: dict[term, dict{df, idf}]`: vocabulary with all terms. Values contain objects with document frequency and idf for selected measure\n",
    "* `index: dict[term, list[tuple[int, int]]]`: inverted index mapping terms to postings. Postings contain doc_id and term frequency sorted by doc_id\n",
    "  \n",
    "The vector space model support 5 measures: `dot`, `cosine`, `bm25`, `bm25-nolen`, `bm25-pos`. The index needs to be rebuilt if the measure is changed (we normalize all documents and the measure imapcts normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class VSModel:\n",
    "    \"\"\"\n",
    "        Generic class for the evaluation of the vector space model, inherited by the document-at-a-time (DAAT) and \n",
    "        term-at-a-time (TAAT) models. \n",
    "    \"\"\"\n",
    "    def __init__(self, collection: list[dict] = None, measure: str = 'dot', remove_stopwords: bool = True):\n",
    "        self.build_index(collection or [], measure, remove_stopwords)\n",
    "    \n",
    "    def _add_document(self, doc: dict):\n",
    "        self.n_docs += 1\n",
    "        doc_id = doc['id'] = self.n_docs\n",
    "        self.documents[doc_id] = doc\n",
    "        # create vector from str-properties\n",
    "        text = ' '.join([value for key, value in doc.items() if type(value) == str])\n",
    "        doc['vector'] = analyzer.bag_of_words(text, remove_stopwords = self.remove_stopwords)\n",
    "        doc['len'] = sum(doc['vector'].values())\n",
    "        # add to vocabulary and count document frequency\n",
    "        for term, tf in doc['vector'].items():\n",
    "            self.vocabulary[term] = self.vocabulary.get(term, 0) + 1\n",
    "    \n",
    "    def _build_vocabulary(self):\n",
    "        idf_func = self.measure in ['bm25', 'bm25-nolen', 'bm25-pos'] and idf_bm25 or idf\n",
    "        self.vocabulary = dict([(term, {'df': df, 'idf': idf_func(df, self.n_docs)}) for term, df in self.vocabulary.items()])\n",
    "\n",
    "    def _normalize_vectors(self):\n",
    "        BM25['adl'] = sum([doc['len'] for doc in self.documents.values()]) / self.n_docs\n",
    "        for doc_id, doc in self.documents.items():\n",
    "            doc['norm-vector'] = normalize_doc_vector(doc['vector'], self.vocabulary, self.measure)\n",
    "\n",
    "    def _build_postings(self):\n",
    "        for doc_id, doc in self.documents.items():\n",
    "            for term, tf_norm in doc['norm-vector'].items():\n",
    "                self.index.setdefault(term, []).append((doc_id, tf_norm))\n",
    "\n",
    "    def build_index(self, collection: list[dict], measure: str = 'dot', remove_stopwords: bool = True):\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.measure = measure\n",
    "        self.n_docs = 0\n",
    "        self.doc_len_sum = 0\n",
    "        self.documents = {}\n",
    "        self.index = {}\n",
    "        self.vocabulary = {}\n",
    "        # load all documents\n",
    "        for doc in collection:\n",
    "            self._add_document(doc)\n",
    "        # finalize the index with idf, normalization, and the postings\n",
    "        if self.n_docs:\n",
    "            self._build_vocabulary()\n",
    "            self._normalize_vectors()\n",
    "            self._build_postings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSModel(VSModel):\n",
    "    \"\"\"\n",
    "        Generic class for the evaluation of the Vector Space model, inherited by the document-at-a-time (DAAT) and \n",
    "        term-at-a-time (TAAT) implementation. This superclass defines the idf-weights including filtering the most\n",
    "        important terms.\n",
    "    \"\"\"\n",
    "    def query_weights(self, vector: dict[str, int], measure: str) -> list[tuple[str,float]]:\n",
    "        # remove terms not in vocabulary\n",
    "        terms = list(filter(lambda t: t in self.vocabulary, vector.keys()))\n",
    "        # dot product: multiply tf with idf\n",
    "        if measure == 'dot':\n",
    "            return list(map(lambda t: (t, vector[t] * self.vocabulary[t]['idf']), terms))\n",
    "        # cosine measure: multiply tf with idf and take the cosine of the sum  \n",
    "        if measure == 'cosine':\n",
    "            norm = sum([(tf * self.vocabulary[term]['idf']) ** 2 for term, tf in vector.items()]) ** 0.5\n",
    "            return list(map(lambda t: (t, vector[t] * self.vocabulary[t]['idf'] / norm), terms))\n",
    "        # bm25: ignore tf and just use idf of term as weight\n",
    "        if measure in ['bm25', 'bm25-nolen', 'bm25-pos']:\n",
    "            return list(map(lambda t: (t, self.vocabulary[t]['idf']), terms))\n",
    "     \n",
    "        raise ValueError('Unknown normalization measure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-at-a-time for Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSModel_DAAT(VSModel):\n",
    "    \"\"\"\n",
    "        Implements the DAAT model for the Vector Space model using inverted index method.\n",
    "    \"\"\"\n",
    "    def search(self, query: str, k: int, measure: str = 'dot', predicate: Callable[[int], bool] = None, selected_docs: set[int] = None):\n",
    "        query_vector = analyzer.bag_of_words(query)\n",
    "\n",
    "        # filter terms and obtain c_j-weights for terms in order of their importance \n",
    "        term_weights = self.query_weights(query_vector, measure)\n",
    "\n",
    "        # get iterators for each term and fetch first posting; postings have form (term, tf)\n",
    "        iters = [iter(self.index[term]) for (term, _) in term_weights]\n",
    "        nexts = [next(iter, None) for iter in iters]\n",
    "\n",
    "        # keep track of all retrieved documents and their score; stored as tuples (doc_id, score)\n",
    "        topk = TopKList(k, term_weights, predicate)\n",
    "\n",
    "        # iterate through all streams and calculate score for smallest doc id\n",
    "        while not all(e is None for e in nexts):\n",
    "            # get smallest value from nexts, ignoring None values\n",
    "            smallest = min(nexts, key = lambda x: x and x[0] or math.inf)[0]\n",
    "            # if selected_docs is given and smallest is not in selected_docs, skip this document\n",
    "            if selected_docs == None or smallest in selected_docs:\n",
    "                # if so, add it to topk\n",
    "                score = sum([nexts[i][1] * term_weights[i][1] for i in range(len(nexts)) if nexts[i] and nexts[i][0] == smallest])\n",
    "                topk.add(smallest, score)\n",
    "            # for each entry in nexts, fetch next item if entry equals smallest\n",
    "            for i, e in enumerate(nexts):\n",
    "                if e and e[0] == smallest:\n",
    "                    nexts[i] = next(iters[i], None)\n",
    "        \n",
    "        # finsihed, return topk for result iteration\n",
    "        return topk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-at-a-time for Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56b33274e3a411b8a4f132bd937aeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(options=('random', 'imdb movies'), value='random'), Dropdown(options=('dot', 'cosine',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "opt_strategy = widgets.Dropdown(options=['document-at-a-time', 'term-at-a-time'])\n",
    "opt_dataset = widgets.Dropdown(options=['random', 'imdb movies'])\n",
    "opt_measure = widgets.Dropdown(options=['dot', 'cosine', 'bm25', 'bm25-pos', 'bm25-nolen'])\n",
    "display(widgets.HBox([opt_dataset, opt_measure, opt_strategy, ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import table\n",
    "from datasets import random as random_docs, imdb as imdb_docs\n",
    "import random\n",
    "\n",
    "def build_index_for_selection(dataset, measure, strategy):\n",
    "    global retriever, collection, queries, predicates, selections\n",
    "    # select the strategy of the retrieval model\n",
    "    if opt_strategy.value == 'document-at-a-time':\n",
    "        retriever = VSModel_DAAT()\n",
    "    else:\n",
    "        retriever = VSModel_TAAT()\n",
    "\n",
    "    # select the dataset and define feedback function, queries, predicates, and selections\n",
    "    if opt_dataset.value == 'random':\n",
    "        collection = random_docs\n",
    "        assessments = {\n",
    "            'random': lambda id: random.random() < 0.8,\n",
    "            'id < 20': lambda id: id < 20,\n",
    "        }\n",
    "        queries = [\n",
    "            'cat dog',\n",
    "            'horse bird',\n",
    "            'cat dog horse bird'\n",
    "        ]\n",
    "        predicates = {\n",
    "            'even doc ids': lambda id: id % 2 == 0,\n",
    "            'odd doc ids': lambda id: id % 2 == 1,\n",
    "        }\n",
    "        selections = {\n",
    "            'doc<10': list(range(10)),\n",
    "        }\n",
    "    elif opt_dataset.value == 'imdb movies':\n",
    "        collection = imdb_docs\n",
    "        assessments = {\n",
    "            'top-100': lambda id: id < 100,\n",
    "            'star in title': lambda id: 'star' in retriever.documents[id]['title'].lower(),\n",
    "            'morgan in actor': lambda id: 'morgan' in retriever.documents[id]['actors'].lower(),\n",
    "            'comedy in genre': lambda id: 'comedy' in retriever.documents[id]['genre'].lower(),\n",
    "        }\n",
    "        queries = [\n",
    "            'star wars', \n",
    "            'drama morgan freeman', \n",
    "            'comedy'\n",
    "        ]\n",
    "        predicates = {\n",
    "            'year < 1990': lambda id: retriever.documents[id]['year'] < 1990,\n",
    "            'year >= 1990': lambda id: retriever.documents[id]['year'] >= 1990,\n",
    "        }\n",
    "        selections = {\n",
    "            'top-100': list(range(100)),\n",
    "            'top-250': list(range(250)),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"to be implemented\")\n",
    "\n",
    "    # build index\n",
    "    retriever.build_index(collection.load(), opt_measure.value)\n",
    "\n",
    "build_index_for_selection(opt_dataset.value, opt_measure.value, opt_strategy.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   id | text                                                                                          |\n",
      "|------|-----------------------------------------------------------------------------------------------|\n",
      "|    1 | dog dog ant ant ant ant                                                                       |\n",
      "|    2 | rabit rabit                                                                                   |\n",
      "|    3 | dog dog dog dog rabit rabit rabit rabit bear bear bee                                         |\n",
      "|    4 | horse tiger tiger tiger tiger bird donkey donkey ant                                          |\n",
      "|    5 | dog dog dog dog cat cat cat rabit fly fly                                                     |\n",
      "|    6 | bird bird bird bird                                                                           |\n",
      "|    7 | horse horse lion lion lion fly fly fly fly                                                    |\n",
      "|    8 | rabit rabit rabit rabit bird bird bird bird donkey donkey donkey donkey fly fly fly wale wale |\n",
      "|    9 | horse horse horse horse horse rabit rabit rabit bird donkey bee bee bee bee bee               |\n",
      "|   10 | fish                                                                                          |\n",
      "\n",
      "| term    |   df |   idf | posting                                                                                                                                                                                                                                                                                                                               |\n",
      "|---------|------|-------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| dog     |   30 |  1.18 | 1 (2.36), 3 (4.72), 5 (4.72), 12 (3.54), 17 (1.18), 22 (2.36), 23 (4.72), 27 (3.54), 32 (2.36), 33 (4.72), 34 (1.18), 38 (1.18), 41 (3.54), 42 (3.54), 43 (4.72), 46 (1.18), 47 (5.91), 48 (1.18), 49 (4.72), 51 (3.54), 62 (1.18), 75 (2.36), 82 (5.91), 84 (4.72), 85 (1.18), 90 (1.18), 91 (2.36), 92 (2.36), 95 (5.91), 99 (2.36) |\n",
      "| cat     |   25 |  1.36 | 5 (4.07), 13 (6.79), 15 (4.07), 25 (6.79), 26 (4.07), 37 (1.36), 38 (1.36), 52 (6.79), 55 (4.07), 56 (6.79), 57 (1.36), 58 (2.71), 59 (2.71), 63 (4.07), 64 (1.36), 70 (6.79), 74 (5.43), 76 (5.43), 79 (2.71), 80 (2.71), 82 (2.71), 89 (4.07), 90 (4.07), 96 (2.71), 97 (1.36)                                                      |\n",
      "| horse   |   22 |  1.48 | 4 (1.48), 7 (2.96), 9 (7.4), 11 (4.44), 14 (4.44), 17 (2.96), 26 (1.48), 39 (5.92), 41 (7.4), 45 (5.92), 49 (4.44), 53 (5.92), 55 (1.48), 58 (7.4), 60 (7.4), 67 (5.92), 69 (1.48), 70 (5.92), 75 (7.4), 85 (5.92), 86 (1.48), 89 (1.48)                                                                                              |\n",
      "| rabit   |   20 |  1.57 | 2 (3.14), 3 (6.28), 5 (1.57), 8 (6.28), 9 (4.71), 14 (7.85), 30 (7.85), 34 (6.28), 43 (6.28), 47 (1.57), 49 (3.14), 52 (3.14), 62 (7.85), 63 (6.28), 69 (4.71), 73 (1.57), 75 (6.28), 81 (6.28), 88 (1.57), 99 (7.85)                                                                                                                 |\n",
      "| ostrich |   18 |  1.67 | 11 (8.35), 17 (8.35), 24 (6.68), 25 (3.34), 28 (1.67), 30 (5.01), 31 (3.34), 50 (8.35), 51 (3.34), 52 (3.34), 65 (6.68), 71 (3.34), 74 (6.68), 77 (3.34), 81 (5.01), 92 (5.01), 93 (5.01), 100 (1.67)                                                                                                                                 |\n",
      "| bear    |   17 |  1.72 | 3 (3.45), 16 (6.9), 20 (1.72), 22 (6.9), 35 (3.45), 42 (6.9), 43 (3.45), 44 (5.17), 45 (6.9), 47 (5.17), 63 (6.9), 64 (3.45), 70 (5.17), 86 (3.45), 88 (1.72), 93 (5.17), 97 (6.9)                                                                                                                                                    |\n",
      "| tiger   |   15 |  1.84 | 4 (7.37), 17 (5.53), 21 (5.53), 29 (5.53), 33 (1.84), 38 (3.69), 58 (7.37), 59 (1.84), 72 (7.37), 73 (3.69), 74 (5.53), 79 (1.84), 91 (1.84), 94 (3.69), 98 (9.21)                                                                                                                                                                    |\n",
      "| bird    |   14 |  1.91 | 4 (1.91), 6 (7.63), 8 (7.63), 9 (1.91), 36 (9.54), 45 (9.54), 48 (5.72), 49 (1.91), 75 (5.72), 86 (7.63), 87 (5.72), 90 (5.72), 92 (5.72), 93 (5.72)                                                                                                                                                                                  |\n",
      "| lion    |   14 |  1.91 | 7 (5.72), 11 (7.63), 26 (5.72), 33 (7.63), 38 (1.91), 43 (1.91), 49 (1.91), 68 (1.91), 69 (9.54), 73 (5.72), 83 (5.72), 94 (3.81), 97 (5.72), 98 (5.72)                                                                                                                                                                               |\n",
      "| donkey  |   13 |  1.98 | 4 (3.95), 8 (7.9), 9 (1.98), 15 (1.98), 29 (3.95), 44 (3.95), 45 (7.9), 49 (1.98), 54 (9.88), 61 (3.95), 77 (3.95), 78 (7.9), 89 (7.9)                                                                                                                                                                                                |\n",
      "| ant     |   12 |  2.05 | 1 (8.2), 4 (2.05), 19 (8.2), 25 (6.15), 26 (2.05), 31 (6.15), 50 (6.15), 57 (10.25), 68 (4.1), 89 (10.25), 96 (6.15), 97 (8.2)                                                                                                                                                                                                        |\n",
      "| bee     |   12 |  2.05 | 3 (2.05), 9 (10.25), 13 (4.1), 19 (2.05), 25 (10.25), 29 (2.05), 33 (2.05), 34 (6.15), 48 (10.25), 67 (4.1), 68 (6.15), 96 (6.15)                                                                                                                                                                                                     |\n",
      "| fly     |   11 |  2.13 | 5 (4.26), 7 (8.52), 8 (6.39), 11 (2.13), 20 (2.13), 50 (2.13), 63 (2.13), 78 (4.26), 84 (10.65), 89 (2.13), 97 (2.13)                                                                                                                                                                                                                 |\n",
      "| wale    |   11 |  2.13 | 8 (4.26), 31 (10.65), 42 (6.39), 48 (8.52), 55 (10.65), 56 (4.26), 62 (6.39), 75 (4.26), 76 (4.26), 83 (2.13), 94 (4.26)                                                                                                                                                                                                              |\n",
      "| snake   |   10 |  2.22 | 28 (2.22), 29 (11.09), 33 (4.43), 40 (2.22), 45 (8.87), 47 (6.65), 70 (4.43), 74 (4.43), 77 (4.43), 84 (2.22)                                                                                                                                                                                                                         |\n",
      "| fish    |    3 |  3.23 | 10 (3.23), 18 (3.23), 66 (3.23)                                                                                                                                                                                                                                                                                                       |\n",
      "\n",
      "100 documents in collection\n",
      "16 distinct terms in collection\n",
      "247 postings\n"
     ]
    }
   ],
   "source": [
    "table.print([collection.format(doc) for doc in retriever.documents.values()], collection.headers(), max_rows = 10)\n",
    "table.print(sorted([[term, term_data['df'], round(term_data['idf'], 2), ', '.join([f'{doc_id} ({round(w, 2)})' for doc_id, w in retriever.index[term]])] for term, term_data in retriever.vocabulary.items()], key=lambda x: -x[1]), ['term', 'df', 'idf', 'posting'], max_rows=20)\n",
    "\n",
    "print(f'{len(retriever.documents)} documents in collection')\n",
    "print(f'{len(retriever.vocabulary)} distinct terms in collection')\n",
    "print('{count} postings'.format(count=sum([len(postings) for postings in retriever.index.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty printing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topk(topk: TopKList):\n",
    "    list = []\n",
    "    for entry in topk:\n",
    "        list.append(collection.format(retriever.documents[entry['id']], [\n",
    "            entry['rank'],\n",
    "            round(entry['score'], 2)\n",
    "        ]))\n",
    "    table.print(list, collection.headers('rel', 'score'), max_rows=len(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching with selected data set and similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\home\\work\\mmir\\mmir-unibasel\\chapter03\\VectorSpace_InvertedIndex.ipynb Cell 29\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# build the widgets\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m form_data \u001b[39m=\u001b[39m widgets\u001b[39m.\u001b[39mHBox([opt_dataset, opt_measure, opt_strategy], layout \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmargin\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m0px 0px 20px\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m opt_dataset\u001b[39m.\u001b[39munobserve(update_dataset, \u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# build query form\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m form_query \u001b[39m=\u001b[39m widgets\u001b[39m.\u001b[39minteractive(run_query,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     query\u001b[39m=\u001b[39mwidgets\u001b[39m.\u001b[39mDropdown(description\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m, options\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(queries)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     k\u001b[39m=\u001b[39mwidgets\u001b[39m.\u001b[39mIntSlider(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, value\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     predicate\u001b[39m=\u001b[39mwidgets\u001b[39m.\u001b[39mDropdown(description\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredicate\u001b[39m\u001b[39m'\u001b[39m,options\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m<none>\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(predicates\u001b[39m.\u001b[39mkeys())),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     selection\u001b[39m=\u001b[39mwidgets\u001b[39m.\u001b[39mDropdown(description\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mselection\u001b[39m\u001b[39m'\u001b[39m,options\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m<none>\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(selections\u001b[39m.\u001b[39mkeys())),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter03/VectorSpace_InvertedIndex.ipynb#Y134sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\env\\python310\\lib\\site-packages\\traitlets\\traitlets.py:1544\u001b[0m, in \u001b[0;36mHasTraits.unobserve\u001b[1;34m(self, handler, names, type)\u001b[0m\n\u001b[0;32m   1542\u001b[0m names \u001b[39m=\u001b[39m parse_notifier_name(names)\n\u001b[0;32m   1543\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m names:\n\u001b[1;32m-> 1544\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remove_notifiers(handler, n, \u001b[39mtype\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\env\\python310\\lib\\site-packages\\traitlets\\traitlets.py:1451\u001b[0m, in \u001b[0;36mHasTraits._remove_notifiers\u001b[1;34m(self, handler, name, type)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trait_notifiers[name][\u001b[39mtype\u001b[39m]\n\u001b[0;32m   1450\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1451\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trait_notifiers[name][\u001b[39mtype\u001b[39;49m]\u001b[39m.\u001b[39;49mremove(handler)\n\u001b[0;32m   1452\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from functools import reduce\n",
    "\n",
    "def run_query(query: str, k:int, predicate: str, selection: str):\n",
    "    topk = retriever.search(query, k, measure=opt_measure.value, predicate=predicates.get(predicate, None), selected_docs=selections.get(selection, None))\n",
    "    print_topk(topk)\n",
    "    for term in sorted(topk.weights.keys(), key = lambda term: -topk.weights[term]):\n",
    "        print(term.rjust(16), topk.weights[term])\n",
    "\n",
    "def update_dataset(*args):\n",
    "    pass\n",
    "\n",
    "# build the widgets\n",
    "form_data = widgets.HBox([opt_dataset, opt_measure, opt_strategy], layout = {'margin': '0px 0px 20px'})\n",
    "opt_dataset.unobserve_all()\n",
    "opt_dataset.observe(update_dataset, 'value')\n",
    "\n",
    "\n",
    "# build query form\n",
    "form_query = widgets.interactive(run_query,\n",
    "    query=widgets.Dropdown(description='query', options=list(queries)),\n",
    "    k=widgets.IntSlider(min=5, max=50, step=5, value=20),\n",
    "    predicate=widgets.Dropdown(description='predicate',options=['<none>'] + list(predicates.keys())),\n",
    "    selection=widgets.Dropdown(description='selection',options=['<none>'] + list(selections.keys())),\n",
    ")\n",
    "\n",
    "# display\n",
    "display(widgets.VBox([form_data, form_query]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_dataset._trait_notifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e771bb60d0468f9760b67348845eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372119918c914493a2653c367735094c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "int_range = widgets.IntSlider()\n",
    "output2 = widgets.Output()\n",
    "\n",
    "display(int_range, output2)\n",
    "\n",
    "def on_value_change(change):\n",
    "    with output2:\n",
    "        print(change['new'])\n",
    "\n",
    "int_range.observe(on_value_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "235",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m retriever\u001b[39m.\u001b[39;49mdocuments[\u001b[39m235\u001b[39;49m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 235"
     ]
    }
   ],
   "source": [
    "retriever.documents[235]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
