{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean retrieval with inverted files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer & Set of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple', 'function', 'test'}\n",
      "{'is', 'function', 'test', 'for', 'this', 'a', 'simple'}\n"
     ]
    }
   ],
   "source": [
    "from utils.text import classic as analyzer\n",
    "\n",
    "print(analyzer.set_of_words(\"this is a simple test for this function\", remove_stopwords = True))\n",
    "print(analyzer.set_of_words(\"this is a simple test for this function\", remove_stopwords = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Implementation: using set operations on postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Base Retriever Class\n",
    "\n",
    "* `n_docs: int`: number of documents added to index\n",
    "* `documents dict[int, dict{id, vector}]`: collection of documents as dictionary with doc_id as key. Each document is a dictionary with the properties from the dataset and additional properties for the retrieval:\n",
    "  - `id` hold the document id as generated when loading the document; corresponds to the key in documents\n",
    "  - `vector` holds the term freqeuncies as dictionary (key=term, value=term frequency)\n",
    "* `vocabulary: dict[term, int]`: vocabularoy of collection with term as keys and document frequency as values\n",
    "* `index: dict[term, list[int]]`: inverted index mapping terms to postings. Postings contain doc_id sorted by doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanRetriever:\n",
    "    def __init__(self, collection: list[dict] = None, remove_stopwords: bool = True):\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        if collection:\n",
    "            self.build_index(collection)\n",
    "        else:\n",
    "            self._init()\n",
    "\n",
    "    def _init_index(self):\n",
    "        self.n_docs = 0\n",
    "        self.documents = {}\n",
    "        self.index = {}\n",
    "        self.vocabulary = {}\n",
    "    \n",
    "    def add_document(self, doc: dict):\n",
    "        self.n_docs += 1\n",
    "        doc_id = doc['id'] = self.n_docs\n",
    "        self.documents[doc_id] = doc\n",
    "        # create vector from str-properties\n",
    "        text = ' '.join([value for key, value in doc.items() if type(value) == str])\n",
    "        vector = doc['vector'] = analyzer.set_of_words(text, remove_stopwords = self.remove_stopwords)\n",
    "        # add to vocabulary and postings\n",
    "        for term in vector:\n",
    "            self.vocabulary[term] = self.vocabulary.get(term, 0) + 1\n",
    "            self.index.setdefault(term, set()).add(doc_id)\n",
    "    \n",
    "    def build_index(self, collection: list[dict]):\n",
    "        self._init_index()\n",
    "        for doc in collection:\n",
    "            self.add_document(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.output import table\n",
    "from datasets.docs import random\n",
    "\n",
    "retriever = BooleanRetriever(random.load())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "**Let's have a look at the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   id | text              |\n",
      "|------|-------------------|\n",
      "|    1 | cat rabit         |\n",
      "|    2 | rabit             |\n",
      "|    3 | cat bee           |\n",
      "|    4 | bear              |\n",
      "|    5 | bear fly          |\n",
      "|    6 | dog               |\n",
      "|    7 | rabit tiger       |\n",
      "|    8 | dog tiger         |\n",
      "|    9 | cat rabit fly     |\n",
      "|   10 | dog cat ant snake |\n",
      "\n",
      "| term    |   df | posting                                                                                                                |\n",
      "|---------|------|------------------------------------------------------------------------------------------------------------------------|\n",
      "| dog     |   30 | {6, 8, 10, 16, 24, 26, 31, 38, 41, 46, 53, 54, 56, 65, 68, 70, 71, 72, 74, 76, 81, 83, 84, 86, 89, 90, 93, 95, 97, 99} |\n",
      "| cat     |   25 | {1, 3, 9, 10, 12, 14, 28, 29, 33, 34, 41, 51, 63, 65, 68, 69, 73, 78, 79, 80, 89, 90, 93, 94, 100}                     |\n",
      "| horse   |   22 | {19, 22, 24, 32, 33, 34, 35, 36, 37, 50, 56, 58, 64, 65, 67, 75, 80, 90, 93, 94, 95, 96}                               |\n",
      "| rabit   |   20 | {1, 2, 7, 9, 12, 26, 40, 43, 45, 50, 55, 60, 61, 62, 64, 73, 88, 93, 99, 100}                                          |\n",
      "| ostrich |   18 | {96, 97, 67, 71, 75, 14, 47, 81, 18, 19, 51, 54, 56, 57, 60, 29, 95, 63}                                               |\n",
      "| bear    |   17 | {64, 33, 67, 4, 5, 40, 77, 60, 15, 51, 20, 84, 88, 90, 28, 61, 30}                                                     |\n",
      "| tiger   |   15 | {100, 7, 8, 88, 44, 45, 50, 84, 85, 87, 56, 59, 92, 30, 31}                                                            |\n",
      "| lion    |   14 | {64, 98, 99, 40, 42, 12, 45, 78, 82, 56, 59, 29, 94, 63}                                                               |\n",
      "| bird    |   14 | {64, 33, 66, 74, 12, 15, 84, 21, 54, 87, 24, 89, 93, 94}                                                               |\n",
      "| donkey  |   13 | {66, 100, 74, 11, 12, 75, 14, 15, 46, 78, 18, 84, 85}                                                                  |\n",
      "| bee     |   12 | {96, 33, 66, 3, 71, 40, 82, 19, 84, 88, 95, 31}                                                                        |\n",
      "| ant     |   12 | {96, 35, 69, 10, 44, 45, 18, 50, 54, 92, 94, 31}                                                                       |\n",
      "| fly     |   11 | {32, 5, 72, 9, 12, 13, 78, 79, 80, 58, 62}                                                                             |\n",
      "| wale    |   11 | {36, 40, 79, 48, 52, 21, 87, 94, 26, 60, 62}                                                                           |\n",
      "| snake   |   10 | {98, 99, 10, 75, 47, 49, 25, 29, 94, 95}                                                                               |\n",
      "| fish    |    5 | {39, 27, 17, 23, 91}                                                                                                   |\n",
      "\n",
      "100 documents in collection\n",
      "16 distinct terms in collection\n",
      "249 postings\n"
     ]
    }
   ],
   "source": [
    "table.print([random.format(doc) for doc in retriever.documents.values()], random.headers(\"id\"), max_rows = 10)\n",
    "table.print(sorted([[term, df, retriever.index[term]] for term, df in retriever.vocabulary.items()], key=lambda x: -x[1]), ['term', 'df', 'posting'], max_rows=20)\n",
    "\n",
    "print(f'{len(retriever.documents)} documents in collection')\n",
    "print(f'{len(retriever.vocabulary)} distinct terms in collection')\n",
    "print('{count} postings'.format(count=sum([len(postings) for postings in retriever.index.values()])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform set operations to answer boolean queries\n",
    "The next section demonstrates how to perform Boolean queries using the inverted index with set operations. It showcases simple queries, AND, OR, AND-NOT operations, complex queries in disjunctive normal form, and arbitrary queries with NOT operations. The results of these operations on the posting sets are printed for each query scenario.\n",
    "\n",
    "| Boolean Operator | Set Operator for Postings |\n",
    "| :--- | :--- |\n",
    "| cat AND dog | `index['cat'] & index['dog']` |\n",
    "| cat OR dog | `index['cat'] \\| index['dog']` |\n",
    "| cat AND NOT dog | `index['cat'] - index['dog']` |\n",
    "\n",
    "Using these rules, we can evaluate a wide range of Boolean queries. However, there are some limitations:\n",
    "- We cannot evaluate OR-queries when one sub-expression is of the form NOT(expr). While it's technically possible to construct NOT(expr) by using all documents except those returned by expr, this approach becomes inefficient for large collections.\n",
    "- In AND-queries, NOT(expr)-parts need to be re-ordered to the end to apply the `-` set operator. Additionally, at least one element of the AND-query must not be in the form NOT(expr).\n",
    "\n",
    "Indeed, while these limitations may be viewed as constraints in our implementation, they have minimal impact on practical querying scenarios. Queries like \"cat OR NOT(dog)\" don't often align with typical search intentions, as they essentially select all documents except those with the condition \"dog but not cat\", i.e., it can be rephrased as \"NOT(dog AND NOT(cat))\". \n",
    "\n",
    "**Extra challenge: add a parser for Boolean expression and evaluate queries dynamically**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026f26b2fd7e4b498a8d9a0882c534cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='query', options=('cat AND dog', 'cat OR dog', 'horse OR bird', 'ca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# lets do simple queries by hand for cats, dogs, horses, and birds\n",
    "cat = retriever.index['cat']\n",
    "dog = retriever.index['dog']\n",
    "horse = retriever.index['horse']\n",
    "bird = retriever.index['bird']\n",
    "\n",
    "results = {\n",
    "    'cat': cat,\n",
    "    'dog': dog,\n",
    "    'horse': horse,\n",
    "    'bird': bird,\n",
    "    'cat AND dog': cat & dog,\n",
    "    'cat OR dog': cat | dog,\n",
    "    'horse OR bird': horse | bird,\n",
    "    'cat AND NOT(dog)': cat - dog,\n",
    "    'horse AND cat AND NOT(bird)': horse & cat - bird,\n",
    "    'horse AND cat': horse & cat,\n",
    "    '(cat AND dog) OR (horse AND cat AND NOT(bird))': (cat & dog) | (horse & cat - bird),\n",
    "    'horse OR bird': horse | bird,\n",
    "    '(cat OR dog) AND (horse OR bird)': (cat | dog) & (horse | bird),\n",
    "    '(cat OR dog) AND NOT(horse OR bird)': (cat | dog) - (horse | bird)\n",
    "}\n",
    "\n",
    "queries = {\n",
    "    'cat AND dog': ['cat', 'dog', 'cat AND dog'],\n",
    "    'cat OR dog': ['cat', 'dog', 'cat OR dog'],\n",
    "    'horse OR bird': ['horse', 'bird', 'horse OR bird'],\n",
    "    'cat AND NOT(dog)': ['cat', 'dog', 'cat AND NOT(dog)'],\n",
    "    'horse AND cat AND NOT(bird)': ['horse', 'cat', 'bird', 'horse AND cat', 'horse AND cat AND NOT(bird)'],\n",
    "    '(cat AND dog) OR (horse AND cat AND NOT(bird))': ['cat', 'dog', 'horse', 'bird', 'cat AND dog', 'horse AND cat', 'horse AND cat AND NOT(bird)', '(cat AND dog) OR (horse AND cat AND NOT(bird))'],\n",
    "    '(cat OR dog) AND (horse OR bird)': ['cat', 'dog', 'cat OR dog', 'horse OR bird', '(cat OR dog) AND (horse OR bird)'],\n",
    "    '(cat OR dog) AND NOT(horse OR bird)': ['cat', 'dog', 'cat OR dog', 'horse OR bird', '(cat OR dog) AND NOT(horse OR bird)']    \n",
    "}\n",
    "\n",
    "def search_boolean_set(query: str):\n",
    "    table.print([[q, sorted(results[q])] for q in queries[query]], ['query', 'result'])\n",
    "\n",
    "# interactive selection of scenario\n",
    "widgets.interact(search_boolean_set, \n",
    "    query=widgets.Dropdown(options=list(queries.keys())), \n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Implementation: using stream based evaluation\n",
    "\n",
    "The set-based evaluation from above does not scale well with the number of documents. In cases with millions of billions of postings for a term, we want to fetch data from an external storage device (which is also a good idea for persistence). But instead of reading all postings into main memory, we read them as streams sorted by the document IDs. Take the postings of cat and dog as an example:\n",
    "\n",
    "| term | postings|\n",
    "| :-- | :-- |\n",
    "| cat | `[1, 4, 8, 10]` |\n",
    "| dog | `[3, 4, 10, 12]` |\n",
    "\n",
    "To evaluate a query like \"cat AND dog\", we fetch the first entry for each term, that is `1` for cat and `3` for dog. If they are the same, we know that the corresponding document fulfills the predicate. If not, then we read the next entry for the term currently having the smallest doc ID. In our example, we read the next cat posting which is `4`. Again, we have no match, so we progress now postings of dog as it currently has the smallest value. The next posting for dog is `4` which matches with the one of cat; hence, we found our first document and return it (in Python we use generators with `yield` as we also do not want to return all results at once but in batches as the user browses through pages). If we need more results to return, we now fetch the next posting for both terms and repeat. Finally, we find `10` and return it as a second answer. If we need more results, we again fetch the next posting for both terms. But since cat does not have more postings, we can terminate the evaluation and stop iteration (dog still has `12` but we already know from the empty cat postings that it cannot match the query). The following visualizes the approach:\n",
    "\n",
    "|step|cat (next) |dog (next) | action|\n",
    "|:-- |:-- |:-- |:-- |\n",
    "| 1 | `1` | `3` | no match, progress cat |\n",
    "| 2 | `4` | `3` | no match, progress dog |\n",
    "| 3 | `4` | `4` | match, return `4` as result, wait to provide next result, and progress both cat and dog |\n",
    "| 4 | `8` | `10` | no match, progress cat |\n",
    "| 5 | `10` | `10` | match, return `10` as result, wait to provide next result, and progress both cat and dog |\n",
    "| 6 | - | `12` | stop iteration as all cat postings are visited; remaining postings in dog cannot fulfill predicate |\n",
    "\n",
    "The OR-operator is implemented similarly, but the iteration returns every time the smallest entry from a sub-expression. For the example above, the OR-operator would first return `1`, progress cat, return `3`, progress dog, return `4`, progress both cat and dog, return `8`, progress cat, return `10`, progress both cat and dog, and finally return `12`. The evaluation stops when all postings are consumed.\n",
    "\n",
    "The \"cat AND NOT(dog)\" evaluation progress is the same as with the AND flow but results are different (match if cat != dog):\n",
    "\n",
    "|step|cat (next) |dog (next) | action|\n",
    "|:-- |:-- |:-- |:-- |\n",
    "| 1 | `1` | `3` | match, return `1` as result, wait to provide next result, and progress cat |\n",
    "| 2 | `4` | `3` | match but cat is not smallest, so we progress dog |\n",
    "| 3 | `4` | `4` | no match as both have the same value, so we progress both cat and dog |\n",
    "| 4 | `8` | `10` | no match, return `8` as result, wait to provide next result, and progress cat  |\n",
    "| 5 | `10` | `10` | no match as both have the same value, so we progress both cat and dog |\n",
    "| 6 | - | `12` | stop iteration as all cat postings are visited; remaining postings in dog cannot fulfill predicate |\n",
    "\n",
    "Finally, we can apply the same approach for arbitrary nesting of AND and OR operators since each evaluation scheme above yeilds document IDs again in a sorted manner. As with atomic term queries, we can only support NOT operators if they are part of an AND expression which at least has one sub-expression without a NOT at the top-level (a nested NOT deeper in the sub-expression is not a problem)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A representation for Boolean expressions\n",
    "Next, we build a representation for Boolean expressions that allows us to retrieve arbitrary queries with the stream based evaluation scheme introduced above. Each object in the representation relates to a sub-expression in the query that is evaluated in a stream-based manner. By composition, we can aggregate atomic queries over terms to arbitrarily complex Boolean queries. We introduce a class ``Term`` to denote atomic queries, 2 classes ``And`` and ``Or`` that represent the boolean operators with an arbitrary number of operands (which can be of type ``Term``, ``And``, and ``Or``). Finally, we also define a class ``Not`` that acts on a single sub-expression (again of any sub-type). However, we do not allow nesting of ``Not``, and only ``And`` expression can have a sub-expression with ``Not`` (and must have at leas one subexpression without ``Not``). Our implentation of ``Not`` is to mark sub-expression, but the class has no way to evaluate itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atomic term expressions\n",
    "This class implements a retriever for an atomic term query:\n",
    "- `__iter__(self)`: provides an iterator interface for Term to simplify enumeration of results; we use the `retrieve`-generator for that\n",
    "- `retrieve(self)`: implements the generator function enumerating all postings for the term from the index. If `DEBUG = True`, it prints the next posting so we can observe the evaluation later on\n",
    "\n",
    "Note: This class is intentionally kept basic for illustrative purposes. It doesn't involve file reading; rather, it relies on the global `index` object. If needed, we can effortlessly replace the for-loop with file reading operations. However, this change introduces complexities because terms may appear multiple times in a Boolean query (e.g., \"cat AND dog OR cat AND horse\"). Preventing duplicate file reads demands additional buffering logic. Furthermore, for data efficiency, it's advisable to apply compression techniques to reduce the data volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanExpression:\n",
    "    pass\n",
    "\n",
    "class Term(BooleanExpression):\n",
    "    \"\"\"\n",
    "        Boolean expression class for atomic term queries\n",
    "    \"\"\"\n",
    "    def __init__(self, term: str, postings: list[int]):\n",
    "        self.term = term\n",
    "        self.postings = postings\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.retrieve()\n",
    "\n",
    "    def retrieve(self):\n",
    "        for posting in sorted(self.postings):\n",
    "            yield posting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Not\n",
    "\n",
    "This is a simple marker class that the And/Or classes are using to implement (or reject) NOT-expressions. Both iterator and generator functions raise an error when invoked to prevent top-level query evaluation of NOT-expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Not(BooleanExpression):\n",
    "    \"\"\"\n",
    "        Marker class for NOT operator on sub-expression. The retrieve method raises an exception.\n",
    "        When used during AND operation, the retrieve method of the sub-expression is called.\n",
    "    \"\"\"\n",
    "    def __init__(self, expression):\n",
    "        self.expression = expression\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.retrieve()\n",
    "\n",
    "    def retrieve(self):\n",
    "        raise Exception(\"NOT operator not allowed at top-level of query\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class And\n",
    "This class implements (arbitrary) AND-expression with multiple sub-expressions (can be of any type). This class can handle NOT(expr)-type         subexpressions and implements the correct '-' semantics of \"cat AND NOT dog\":\n",
    "- `__iter__(self)`: provides an iterator interface for AND -expression to simplify enumeration of results; we use the `retrieve`-generator for that\n",
    "- `retrieve(self)`: implements the generator function enumerating all postings for the term from the index\n",
    "\n",
    "The implementation is kept simple to illustrate the algorithm, and further optimizations are feasible. The implementation first differentiates between positive and negative expressions (for lack of better words). Positive means sub-expressions without top-level NOT-operator, and negative means sub-expressions with a top-level NOT-operator. The `pos_next` and `neg_next` lists contain the next posting for each of the corresponding sub-expressions. Values are `yield`-ed if all 'positive' expressions equal the smallest value over all sub-expressions, and if none of the 'negative' sub-expressions equals that smallest value. The final 2 for-loops progress sub-expressions that have the smallest value as their next value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class And(BooleanExpression):\n",
    "    \"\"\"\n",
    "        AND-expression with multiple sub-expressions. This operator can handle NOT(expr)-type \n",
    "        subexpressions and implements the correct '-' semantics of \"cat AND NOT dog\".\n",
    "    \"\"\"\n",
    "    def __init__(self, *expressions):\n",
    "        self.expressions = expressions\n",
    "        # select expressison that are not Term or that have x._not = False\n",
    "        self.pos = [e for e in expressions if not isinstance(e, Not)]\n",
    "        self.neg = [e for e in expressions if isinstance(e, Not)]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.retrieve()\n",
    "\n",
    "    def retrieve(self):\n",
    "        pos_stream = [e.retrieve() for e in self.pos]\n",
    "        pos_next = [next(e) for e in pos_stream]\n",
    "        neg_stream = [iter(e.expression.retrieve()) for e in self.neg]\n",
    "        neg_next = [next(e, None) for e in neg_stream]\n",
    "\n",
    "        # iterate until one pos_next element is None\n",
    "        while None not in pos_next:\n",
    "            # get smallest value from pos_next and neg_next, ignoring None values in neg_next\n",
    "            smallest = min(pos_next + neg_next, key=lambda x: x if x is not None else float('inf'))\n",
    "            # check if all entries of pos_next equal smallest, and no entry in neg_next equals smallest\n",
    "            if all(e is smallest for e in pos_next) and smallest not in neg_next:\n",
    "                yield smallest\n",
    "            # for each entry in pos_next and neg_next, fetch next item if entry equals smallest\n",
    "            for i, e in enumerate(pos_next):\n",
    "                if e is smallest:\n",
    "                    pos_next[i] = next(pos_stream[i], None)\n",
    "            for i, e in enumerate(neg_next):\n",
    "                if e is smallest:\n",
    "                    neg_next[i] = next(neg_stream[i], None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Or\n",
    "This class implements (arbitrary) OR-expression with multiple sub-expressions (can be of any type). This class **cannot** handle NOT(expr)-type         subexpressions and raises an error if a sub-expression has a top-level NOT-operator:\n",
    "- `__iter__(self)`: provides an iterator interface for OR-expression to simplify enumeration of results; we use the `retrieve`-generator for that\n",
    "- `retrieve(self)`: implements the generator function enumerating all postings for the term from the index\n",
    "\n",
    "The implementation is kept simple to illustrate the algorithm, and further optimizations are feasible. The implementation `yield`s the smallest values found as next posting in its sub-expressions. Then it progresses sub-expressions with that smallest value as their next element. The iteration stops once all sub-expressions are exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Or(BooleanExpression):\n",
    "    \"\"\"\n",
    "        OR-expression with multiple sub-expressions. This operator cannot handle NOT(expr)-type subexpressions\n",
    "    \"\"\"\n",
    "    def __init__(self, *expressions):\n",
    "        # check that there are no NOT(expr)-type subexpressions\n",
    "        if any(isinstance(e, Not) for e in expressions):\n",
    "            raise Exception(\"OR-expression cannot handle NOT(expr)-type subexpressions\")\n",
    "        self.expressions = expressions\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.retrieve()\n",
    "\n",
    "    def retrieve(self):\n",
    "        iters = [iter(e) for e in self.expressions]\n",
    "        nexts = [next(e, None) for e in iters]\n",
    "\n",
    "        while not all(e is None for e in nexts):\n",
    "            # get smallest value from nexts, ignoring None values\n",
    "            smallest = min(nexts, key=lambda x: x if x is not None else float('inf'))\n",
    "            yield smallest\n",
    "            # for each entry in nexts, fetch next item if entry equals smallest\n",
    "            for i, e in enumerate(nexts):\n",
    "                if e is smallest:\n",
    "                    nexts[i] = next(iters[i], None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing boolean queries\n",
    "\n",
    "We use a simple language in EBNF notation:\n",
    "```\n",
    "  expression := term {\"OR\" term}\n",
    "  term := factor {\"AND\" factor}\n",
    "  factor := <word> | \"NOT\" factor | \"(\" expression \")\"\n",
    "```\n",
    "\n",
    "Given the simple nature of the language, we can use a lexer based on a regular expression such as `\\w+|\\(|\\)` to create tokens from the query string. The parser is manually generated from the EBNF and builds the Boolean expression using the classes introduced above for the current retriever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class BooleanRetriever(BooleanRetriever):\n",
    "    @staticmethod\n",
    "    def format_bool(expr: BooleanExpression) -> str:\n",
    "        \"\"\"\n",
    "            Prints a Boolean expression in a human-readable format.\n",
    "        \"\"\"\n",
    "        if isinstance(expr, And):\n",
    "            return '({})'.format(' AND '.join([BooleanRetriever.format_bool(e) for e in expr.expressions]))\n",
    "        if isinstance(expr, Or):\n",
    "            return '({})'.format(' OR '.join([BooleanRetriever.format_bool(e) for e in expr.expressions]))\n",
    "        if isinstance(expr, Not):\n",
    "            return f\"NOT({BooleanRetriever.format_bool(expr.expression)})\"\n",
    "        return f\"{expr.term}\"\n",
    "    \n",
    "    def parse_query(self, query: str) -> BooleanExpression:\n",
    "        \"\"\"\n",
    "            expression := term {\"OR\" term}\n",
    "            term := factor {\"AND\" factor}\n",
    "            factor := <word> | \"NOT\" factor | \"(\" expression \")\"\n",
    "        \"\"\"\n",
    "        def factor(tokens: list[str]):\n",
    "            if not tokens: raise ValueError(\"parse error\")\n",
    "            if tokens[0] == '(':\n",
    "                tokens.pop(0)\n",
    "                expr = expression(tokens)\n",
    "                if not tokens or tokens[0] != ')': raise ValueError(\"parse error\")\n",
    "                tokens.pop(0)\n",
    "                return expr\n",
    "            if tokens[0] == 'NOT':\n",
    "                tokens.pop(0)\n",
    "                return Not(factor(tokens))\n",
    "            term = tokens.pop(0)\n",
    "            return Term(term, self.index[term])\n",
    "\n",
    "        def term(tokens: list[str]):\n",
    "            expr = [factor(tokens)]\n",
    "            if not tokens or tokens[0] != 'AND':\n",
    "                return expr[0]\n",
    "            while tokens and tokens[0] == 'AND':\n",
    "                tokens.pop(0)\n",
    "                expr.append(factor(tokens))\n",
    "            return And(*expr)    \n",
    "\n",
    "        def expression(tokens: list[str]):\n",
    "            expr = [term(tokens)]\n",
    "            if not tokens or tokens[0] != 'OR': \n",
    "                return expr[0]\n",
    "            while tokens and tokens[0] == 'OR':\n",
    "                tokens.pop(0)\n",
    "                expr.append(term(tokens))\n",
    "            return Or(*expr)\n",
    "\n",
    "        tokens = re.findall(r\"\\w+|\\(|\\)\", query)\n",
    "        return expression(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the query interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanRetriever(BooleanRetriever):\n",
    "    def search(self, query: str) -> list:\n",
    "        return self.parse_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f429a97486ca47d8ba96566caebc5113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='query', options=('cat AND dog', 'cat OR dog', 'horse OR bird', 'ca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever = BooleanRetriever(random.load())\n",
    "\n",
    "queries = {\n",
    "    'cat AND dog': ['cat', 'dog', 'cat AND dog'],\n",
    "    'cat OR dog': ['cat', 'dog', 'cat OR dog'],\n",
    "    'horse OR bird': ['horse', 'bird', 'horse OR bird'],\n",
    "    'cat AND NOT(dog)': ['cat', 'dog', 'cat AND NOT(dog)'],\n",
    "    'horse AND cat AND NOT(bird)': ['horse', 'cat', 'bird', 'horse AND cat', 'horse AND cat AND NOT(bird)'],\n",
    "    '(cat AND dog) OR (horse AND cat AND NOT(bird))': ['cat', 'dog', 'horse', 'bird', 'cat AND dog', 'horse AND cat', 'horse AND cat AND NOT(bird)', '(cat AND dog) OR (horse AND cat AND NOT(bird))'],\n",
    "    '(cat OR dog) AND (horse OR bird)': ['cat', 'dog', 'cat OR dog', 'horse OR bird', '(cat OR dog) AND (horse OR bird)'],\n",
    "    '(cat OR dog) AND NOT(horse OR bird)': ['cat', 'dog', 'cat OR dog', 'horse OR bird', '(cat OR dog) AND NOT(horse OR bird)']    \n",
    "}\n",
    "\n",
    "def search_boolean_stream(query: str):\n",
    "    table.print([[q, list(retriever.search(q))] for q in queries[query]], ['query', 'result'])\n",
    "\n",
    "# interactive selection of scenario\n",
    "widgets.interact(search_boolean_set, \n",
    "    query=widgets.Dropdown(options=list(queries.keys())), \n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic generators\n",
    "\n",
    "Generators are great to prevent evaluation of results that are not needed. Assume the user is querying with \"(cat OR dog) AND NOT(horse OR bird)\" which generates a lot of results. Rather than returning hundreds of results at once, a user may want to browse through results page-by-page. Our generates exactly do this; even more, we only read postings that we need to produce the results for each batch returned to the users as they browse through results.\n",
    "\n",
    "Let's verify this and set `DEBUG = True`. Every time we fetch a posting, the class Term is printing a line with the term and the next posting. The code below first fetches 5 results, and then, as we imagine that the user moves to the next page, fetches the next 5 results. From the produced output, we see that the evaluation indeed only reads postings as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "DEBUG = True\n",
    "\n",
    "expr = And(Or(Term('cat'), Term('dog')), Not(Or(Term('horse'), Term('bird'))))\n",
    "result = expr.retrieve()\n",
    "\n",
    "print(\"retrieving first 2 documents for (cat OR dog) AND NOT(horse OR bird)\")\n",
    "print(list(islice(result, 2)))\n",
    "\n",
    "print(\"\\nretrieving next 2 documents\")\n",
    "print(list(islice(result, 2)))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next\n",
    "We could extend the code to parse query strings and produce the expressions necessary for the evaluation. We could process real documents, create a document and index dictionary to show real text retrieval. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
