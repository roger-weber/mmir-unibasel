{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIR retrieval with inverted files\n",
    "\n",
    "Let's begin by setting up a straightforward scenario involving a handful of terms and assigning random document references to them. Our focus here is to demonstrate the use of inverted files for Boolean retrieval. We will explore two aspects: 1) employing set operators for query evaluation, and 2) utilizing streaming interfaces to efficiently retrieve postings. It's important to note that in this scenario, we are using document IDs instead of actual documents to keep things simple.\n",
    "\n",
    "## Create inverted index\n",
    "The next section generates random inverted index postings for a set of terms. It simulates the indexing process for Boolean retrieval by associating random document IDs with each term. The `vocabulary` dictionary defines terms and their desired document frequencies (as a %-figure). The generated postings are stored in the `index` dictionary, with each term mapped to a set of corresponding document IDs.\n",
    "\n",
    "* `nDocs = 100`: Defines the total number of documents (document IDs) as 100.\n",
    "* `index = {}`: Initializes an empty dictionary to store the postings for each term.\n",
    "* `DEBUG = False`: A debug flag (we use it later to illustrate code execution).\n",
    "* `vocabulary`: Defines a dictionary where each term is associated with its desired document frequency (expressed as a percentage).\n",
    "\n",
    "`createPostings(term: str, docFreq: int = None)` takes a term (string) and an optional document frequency (docFreq, integer) as arguments. It generates random postings for the term by creating a set of document IDs. If docFreq is not provided, it generates a random document frequency between 1 and nDocs. The for-loop iterates through each term in the vocabulary dictionary and calls the createPostings function. For each term, it fetches the desired document frequency from the vocabulary (values are percentages) and passes it to createPostings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "DEBUG = False\n",
    "nDocs = 40\n",
    "index = {}\n",
    "documents = []\n",
    "\n",
    "def createPostings(term: str, docFreq: int = None):\n",
    "    # create random postings for the term for ids between 1 and nDocs\n",
    "    if docFreq is None:\n",
    "        docFreq = random.randint(1, nDocs)\n",
    "    # create sets with random ids\n",
    "    index[term] = set(random.sample(range(1, nDocs + 1), docFreq))\n",
    "    # extend feature vectors for documents\n",
    "    for doc in index[term]:\n",
    "        documents[doc].add(term)\n",
    "\n",
    "# define vocabulary and create random postings with given document frequency (in percents)\n",
    "vocabulary = {\n",
    "    'dog':       33,\n",
    "    'cat':       28,\n",
    "    'horse':     12,\n",
    "    'rabit':     19,\n",
    "    'ostrich':   15,\n",
    "    'bear':      14,\n",
    "    'tiger':     17,\n",
    "    'lion':      15,\n",
    "    'bird':      18\n",
    "}\n",
    "\n",
    "# set all feature vectors of documents to empty. We use sets since BIR uses set-of-word model\n",
    "for doc in range(nDocs + 1):\n",
    "    documents.append(set())\n",
    "\n",
    "# call createPostings for each entry in vocabulary to create the inverted index\n",
    "for word in vocabulary:\n",
    "    createPostings(word, vocabulary[word] * nDocs // 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "Let's have a look at the postings for each term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog        [1, 2, 7, 10, 14, 17, 19, 22, 24, 30, 37, 38, 40]\n",
      "cat        [3, 11, 20, 21, 22, 25, 32, 35, 36, 38, 40]\n",
      "horse      [4, 10, 14, 21]\n",
      "rabit      [5, 6, 22, 28, 35, 38, 39]\n",
      "ostrich    [12, 25, 27, 28, 31, 32]\n",
      "bear       [5, 6, 17, 37, 40]\n",
      "tiger      [2, 17, 23, 25, 34, 37]\n",
      "lion       [9, 11, 14, 17, 21, 38]\n",
      "bird       [4, 10, 14, 19, 27, 31, 39]\n"
     ]
    }
   ],
   "source": [
    "# print postings with term and list of documents\n",
    "for term, posting in index.items():\n",
    "    # format: term + doc_list as array; padd term to 15 characters\n",
    "    print(term.ljust(10), sorted(posting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'dog'}\n",
      "2 {'tiger', 'dog'}\n",
      "3 {'cat'}\n",
      "4 {'horse', 'bird'}\n",
      "5 {'bear', 'rabit'}\n",
      "6 {'bear', 'rabit'}\n",
      "7 {'dog'}\n",
      "8 set()\n",
      "9 {'lion'}\n",
      "10 {'horse', 'dog', 'bird'}\n",
      "11 {'lion', 'cat'}\n",
      "12 {'ostrich'}\n",
      "13 set()\n",
      "14 {'horse', 'lion', 'dog', 'bird'}\n",
      "15 set()\n",
      "16 set()\n",
      "17 {'bear', 'lion', 'tiger', 'dog'}\n",
      "18 set()\n",
      "19 {'dog', 'bird'}\n",
      "20 {'cat'}\n",
      "21 {'horse', 'cat', 'lion'}\n",
      "22 {'cat', 'dog', 'rabit'}\n",
      "23 {'tiger'}\n",
      "24 {'dog'}\n",
      "25 {'tiger', 'ostrich', 'cat'}\n",
      "26 set()\n",
      "27 {'ostrich', 'bird'}\n",
      "28 {'ostrich', 'rabit'}\n",
      "29 set()\n",
      "30 {'dog'}\n",
      "31 {'ostrich', 'bird'}\n",
      "32 {'ostrich', 'cat'}\n",
      "33 set()\n",
      "34 {'tiger'}\n",
      "35 {'cat', 'rabit'}\n",
      "36 {'cat'}\n",
      "37 {'bear', 'tiger', 'dog'}\n",
      "38 {'lion', 'cat', 'dog', 'rabit'}\n",
      "39 {'bird', 'rabit'}\n",
      "40 {'bear', 'cat', 'dog'}\n"
     ]
    }
   ],
   "source": [
    "# print a few documents\n",
    "for doc in range(40):\n",
    "    print(doc + 1, documents[doc + 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Term\n",
    "\n",
    "This class implements a retriever for an atomic term query:\n",
    "- `__iter__(self)`: provides an iterator interface for Term to simplify enumeration of results; we use the `retrieve`-generator for that\n",
    "- `retrieve(self)`: implements the generator function enumerating all postings for the term from the index. If `DEBUG = True`, it prints the next posting so we can observe the evaluation later on\n",
    "\n",
    "Note: This class is intentionally kept basic for illustrative purposes. It doesn't involve file reading; rather, it relies on the global `index` object. If needed, we can effortlessly replace the for-loop with file reading operations. However, this change introduces complexities because terms may appear multiple times in a Boolean query (e.g., \"cat AND dog OR cat AND horse\"). Preventing duplicate file reads demands additional buffering logic. Furthermore, for data efficiency, it's advisable to apply compression techniques to reduce the data volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRPosting:\n",
    "    \"\"\"\n",
    "        Stream of postings for BIR retrieval. Iterator/generator returns only the document IDs.\n",
    "        Method weight provides the BIR weights that can be adjusted with relevance feedback\n",
    "    \"\"\"\n",
    "    def __init__(self, term: str, feedback = {}):\n",
    "        self.term = term\n",
    "        self.docFreq = len(index[term])\n",
    "        self.weight = (self.docFreq + 1) / (nDocs + 1)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.retrieve()\n",
    "\n",
    "    def retrieve(self):\n",
    "        for posting in sorted(index[self.term]):\n",
    "            if DEBUG:\n",
    "                print(self.term, posting)\n",
    "            yield posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog        0.34146341463414637 [1, 2, 7, 10, 14, 17, 19, 22, 24, 30, 37, 38, 40]\n",
      "cat        0.2926829268292683 [3, 11, 20, 21, 22, 25, 32, 35, 36, 38, 40]\n",
      "horse      0.12195121951219512 [4, 10, 14, 21]\n",
      "rabit      0.1951219512195122 [5, 6, 22, 28, 35, 38, 39]\n",
      "ostrich    0.17073170731707318 [12, 25, 27, 28, 31, 32]\n",
      "bear       0.14634146341463414 [5, 6, 17, 37, 40]\n",
      "tiger      0.17073170731707318 [2, 17, 23, 25, 34, 37]\n",
      "lion       0.17073170731707318 [9, 11, 14, 17, 21, 38]\n",
      "bird       0.1951219512195122 [4, 10, 14, 19, 27, 31, 39]\n"
     ]
    }
   ],
   "source": [
    "# print postings with term and list of documents\n",
    "for term, posting in index.items():\n",
    "    # format: term + doc_list as array; padd term to 15 characters\n",
    "    print(term.ljust(10), BIRPosting(term).weight, sorted(posting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRModel_DAAT:\n",
    "    \"\"\"\n",
    "        Document at a time\n",
    "    \"\"\"\n",
    "    def __init__(self, terms):\n",
    "        self.terms = [BIRPosting(term) for term in terms]\n",
    "        self.visited = set()\n",
    "        self.relevant = set()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.retrieve()\n",
    "\n",
    "    def _score(self, indexes: list):\n",
    "        score = 0\n",
    "        for i in indexes:\n",
    "            score += self.terms[i].weight\n",
    "        return score\n",
    "\n",
    "    def retrieve(self):\n",
    "        iters = [iter(e) for e in self.terms]\n",
    "        nexts = [next(e, None) for e in iters]\n",
    "\n",
    "        while not all(e is None for e in nexts):\n",
    "            # get smallest value from nexts, ignoring None values\n",
    "            smallest = min(nexts, key=lambda x: x if x is not None else float('inf'))\n",
    "            terms = [index for index in range(len(nexts)) if doc == smallest]\n",
    "            print(smallest, nexts, terms)\n",
    "            yield (smallest, self._score(terms))\n",
    "            # for each entry in nexts, fetch next item if entry equals smallest\n",
    "            for i, e in enumerate(nexts):\n",
    "                if e is smallest:\n",
    "                    nexts[i] = next(iters[i], None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample queries and comparison with set-based implementation\n",
    "\n",
    "We compute the same queries as above, but this time constructing them with the classes defined above. Using iterators and generators greatly simplifies the evaluation queries. Although, in all the examples below we fetch all results, we will see in the next section that we truly generate results with minimal efforts.\n",
    "\n",
    "Assertion verify that we have correctly implemented operator evaluations. Do we still have bugs in the implementation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cat dog [(1, 0), (2, 0), (3, 0), (7, 0), (10, 0), (11, 0), (14, 0), (17, 0), (19, 0), (20, 0), (21, 0), (22, 0), (24, 0), (25, 0), (30, 0), (32, 0), (35, 0), (36, 0), (37, 0), (38, 0), (40, 0)]\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# AND operator\n",
    "query = ['cat', 'dog']\n",
    "bir = BIRModel_DAAT(query)\n",
    "print(' '.join(query).rjust(45), sorted(bir))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic generators\n",
    "\n",
    "Generators are great to prevent evaluation of results that are not needed. Assume the user is querying with \"(cat OR dog) AND NOT(horse OR bird)\" which generates a lot of results. Rather than returning hundreds of results at once, a user may want to browse through results page-by-page. Our generates exactly do this; even more, we only read postings that we need to produce the results for each batch returned to the users as they browse through results.\n",
    "\n",
    "Let's verify this and set `DEBUG = True`. Every time we fetch a posting, the class Term is printing a line with the term and the next posting. The code below first fetches 5 results, and then, as we imagine that the user moves to the next page, fetches the next 5 results. From the produced output, we see that the evaluation indeed only reads postings as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving first 5 documents for (cat OR dog) AND NOT(horse OR bird)\n",
      "cat 4\n",
      "dog 1\n",
      "horse 6\n",
      "bird 2\n",
      "dog 3\n",
      "bird 3\n",
      "dog 4\n",
      "bird 8\n",
      "cat 5\n",
      "dog 6\n",
      "cat 12\n",
      "dog 9\n",
      "horse 10\n",
      "bird 15\n",
      "dog 10\n",
      "dog 13\n",
      "horse 11\n",
      "horse 14\n",
      "[1, 4, 5, 9, 12]\n",
      "\n",
      "retrieving next 5 documents\n",
      "cat 13\n",
      "cat 14\n",
      "dog 21\n",
      "cat 15\n",
      "cat 20\n",
      "bird 26\n",
      "cat 22\n",
      "dog 22\n",
      "cat 30\n",
      "dog 23\n",
      "[13, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "DEBUG = True\n",
    "\n",
    "expr = And(Or(Term('cat'), Term('dog')), Not(Or(Term('horse'), Term('bird'))))\n",
    "result = expr.retrieve()\n",
    "\n",
    "print(\"retrieving first 5 documents for (cat OR dog) AND NOT(horse OR bird)\")\n",
    "print(list(islice(result, 5)))\n",
    "\n",
    "print(\"\\nretrieving next 5 documents\")\n",
    "print(list(islice(result, 5)))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next\n",
    "We could extend the code to parse query strings and produce the expressions necessary for the evaluation. We could process real documents, create a document and index dictionary to show real text retrieval. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
