{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS and NER tagging of dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Project Gutenberg, 244: A Study in Scarlet (en), Arthur Conan Doyle\n",
    "text_en = \"\"\"\n",
    "This was a lofty chamber, lined and littered with countless bottles.\n",
    "Broad, low tables were scattered about, which bristled with retorts,\n",
    "test-tubes, and little Bunsen lamps, with their blue flickering flames.\n",
    "There was only one student in the room, who was bending over a distant\n",
    "table absorbed in his work. At the sound of our steps he glanced round\n",
    "and sprang to his feet with a cry of pleasure. “I’ve found it! I’ve\n",
    "found it,” he shouted to my companion, running towards us with a\n",
    "test-tube in his hand. “I have found a re-agent which is precipitated\n",
    "by hæmoglobin, and by nothing else.” Had he discovered a gold mine,\n",
    "greater delight could not have shone upon his features.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'was',\n",
       " 'a',\n",
       " 'lofty',\n",
       " 'chamber',\n",
       " ',',\n",
       " 'lined',\n",
       " 'and',\n",
       " 'littered',\n",
       " 'with',\n",
       " 'countless',\n",
       " 'bottles',\n",
       " '.',\n",
       " '\\n',\n",
       " 'Broad',\n",
       " ',',\n",
       " 'low',\n",
       " 'tables',\n",
       " 'were',\n",
       " 'scattered',\n",
       " 'about',\n",
       " ',',\n",
       " 'which',\n",
       " 'bristled',\n",
       " 'with',\n",
       " 'retorts',\n",
       " ',',\n",
       " '\\n',\n",
       " 'test',\n",
       " '-',\n",
       " 'tubes',\n",
       " ',',\n",
       " 'and',\n",
       " 'little',\n",
       " 'Bunsen',\n",
       " 'lamps',\n",
       " ',',\n",
       " 'with',\n",
       " 'their',\n",
       " 'blue',\n",
       " 'flickering',\n",
       " 'flames',\n",
       " '.',\n",
       " '\\n',\n",
       " 'There',\n",
       " 'was',\n",
       " 'only',\n",
       " 'one',\n",
       " 'student',\n",
       " 'in',\n",
       " 'the',\n",
       " 'room',\n",
       " ',',\n",
       " 'who',\n",
       " 'was',\n",
       " 'bending',\n",
       " 'over',\n",
       " 'a',\n",
       " 'distant',\n",
       " '\\n',\n",
       " 'table',\n",
       " 'absorbed',\n",
       " 'in',\n",
       " 'his',\n",
       " 'work',\n",
       " '.',\n",
       " 'At',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'of',\n",
       " 'our',\n",
       " 'steps',\n",
       " 'he',\n",
       " 'glanced',\n",
       " 'round',\n",
       " '\\n',\n",
       " 'and',\n",
       " 'sprang',\n",
       " 'to',\n",
       " 'his',\n",
       " 'feet',\n",
       " 'with',\n",
       " 'a',\n",
       " 'cry',\n",
       " 'of',\n",
       " 'pleasure',\n",
       " '.',\n",
       " '“',\n",
       " 'I',\n",
       " '’ve',\n",
       " 'found',\n",
       " 'it',\n",
       " '!',\n",
       " 'I',\n",
       " '’ve',\n",
       " '\\n',\n",
       " 'found',\n",
       " 'it',\n",
       " ',',\n",
       " '”',\n",
       " 'he',\n",
       " 'shouted',\n",
       " 'to',\n",
       " 'my',\n",
       " 'companion',\n",
       " ',',\n",
       " 'running',\n",
       " 'towards',\n",
       " 'us',\n",
       " 'with',\n",
       " 'a',\n",
       " '\\n',\n",
       " 'test',\n",
       " '-',\n",
       " 'tube',\n",
       " 'in',\n",
       " 'his',\n",
       " 'hand',\n",
       " '.',\n",
       " '“',\n",
       " 'I',\n",
       " 'have',\n",
       " 'found',\n",
       " 'a',\n",
       " 're',\n",
       " '-',\n",
       " 'agent',\n",
       " 'which',\n",
       " 'is',\n",
       " 'precipitated',\n",
       " '\\n',\n",
       " 'by',\n",
       " 'hæmoglobin',\n",
       " ',',\n",
       " 'and',\n",
       " 'by',\n",
       " 'nothing',\n",
       " 'else',\n",
       " '.',\n",
       " '”',\n",
       " 'Had',\n",
       " 'he',\n",
       " 'discovered',\n",
       " 'a',\n",
       " 'gold',\n",
       " 'mine',\n",
       " ',',\n",
       " '\\n',\n",
       " 'greater',\n",
       " 'delight',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have',\n",
       " 'shone',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'features',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nlp(text_en)\n",
    "[token.text for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tokens(lookup: dict, name: str, tagged_tokens: list[tuple[str,str]]):\n",
    "  for token, tag in tagged_tokens:\n",
    "    if not token.isalpha():\n",
    "      continue\n",
    "    if not token in lookup:\n",
    "      lookup[token] = {'token': token}\n",
    "    lookup[token][name] = tag\n",
    "\n",
    "def get_pos_nltk(text: str, tagset: str=None):\n",
    "  tokens = nltk.word_tokenize(text_en)\n",
    "  return nltk.pos_tag(tokens, tagset=tagset)\n",
    "\n",
    "def get_pos_spacy(text: str):\n",
    "  tokens = nlp(text)\n",
    "  return [(token.text, token.pos_) for token in tokens]\n",
    "\n",
    "\n",
    "lookup = {}\n",
    "add_tokens(lookup, 'nltk(standard)', get_pos_nltk(text_en))\n",
    "add_tokens(lookup, 'nltk(universal)', get_pos_nltk(text_en, 'universal'))\n",
    "add_tokens(lookup, 'spaCy', get_pos_spacy(text_en))\n",
    "# list(lookup.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'spaCy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\home\\work\\mmir\\mmir-unibasel\\chapter04\\tagging.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter04/tagging.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rows \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter04/tagging.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m lookup\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter04/tagging.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   rows\u001b[39m.\u001b[39mappend([e[\u001b[39m'\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m'\u001b[39m], e[\u001b[39m'\u001b[39m\u001b[39mnltk(standard)\u001b[39m\u001b[39m'\u001b[39m],e[\u001b[39m'\u001b[39m\u001b[39mnltk(universal)\u001b[39m\u001b[39m'\u001b[39m],e[\u001b[39m'\u001b[39m\u001b[39mspaCy\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/home/work/mmir/mmir-unibasel/chapter04/tagging.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m Markdown(tabulate(rows, headers))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'spaCy'"
     ]
    }
   ],
   "source": [
    "headers = ['term', 'nltk (pos)', 'nltk (universal)', 'spaCy', 'LLM']\n",
    "rows = []\n",
    "\n",
    "for e in lookup.values():\n",
    "  rows.append([e['token'], e['nltk(standard)'],e['nltk(universal)'],e['spaCy']])\n",
    "\n",
    "Markdown(tabulate(rows, headers))\n",
    "\n",
    "\n",
    "\n",
    "# for token in nltk.word_tokenize(text_en):\n",
    "#   if not token.isalpha():\n",
    "#     continue\n",
    "#   row = [token]\n",
    "#   row.append(nltk.pos_tag([token]))\n",
    "#   row.append(nltk.pos_tag([token], tagset='universal'))\n",
    "#   rows.append(row)\n",
    "#   if len(rows) > 30:\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
