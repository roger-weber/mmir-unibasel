{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# get sentences from collection\n",
    "sentences = movie_reviews.sents()\n",
    "print(len(sentences))\n",
    "\n",
    "# train model with window 5, 25 dimensions\n",
    "word_vectors = Word2Vec(sentences, vector_size=25, window=5).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(vector_size=25, window=5, min_count=1)  # instantiate\n",
    "model.build_vocab(corpus_iterable=sentences)\n",
    "model.train(corpus_iterable=sentences, total_examples=len(sentences), epochs=10)\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "# Show all available models in gensim-data\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "\n",
    "# load a pre-trained glove model\n",
    "word_vectors = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_vectors.get_vector('cat'))\n",
    "print(word_vectors.most_similar('cat'))\n",
    "print(word_vectors.most_similar(positive=['paris','germany'], negative=['france']))\n",
    "paris = word_vectors.get_vector('paris')\n",
    "germany = word_vectors.get_vector('germany')\n",
    "france = word_vectors.get_vector('france')\n",
    "print(word_vectors.similar_by_vector(paris+germany-france))\n",
    "print(word_vectors.doesnt_match(\"bird dog cat town\".split()))\n",
    "word_vectors['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar(term):\n",
    "    print(f\"{term:>10}: {', '.join([e[0] for e in word_vectors.most_similar(term) if e[1] > 0.7])}\")\n",
    "    print(f\"{'':>10}  {', '.join([str(e) for e in word_vectors.get_vector(term)][:7])}, ...\")\n",
    "    print()\n",
    "\n",
    "def print_analogy(positive, negative):\n",
    "    left_side = \" + \".join(positive) + \" - \" + \" - \".join(negative)\n",
    "    right_side = ', '.join([e[0] for e in word_vectors.most_similar(positive=positive, negative=negative) if e[1] > 0.1])\n",
    "    print(f\"{left_side:>30} = {right_side}\")\n",
    "\n",
    "def print_doesnt_match(list_of_terms):\n",
    "    if not list_of_terms is list:\n",
    "        list_of_terms = list_of_terms.split()\n",
    "    word = word_vectors.doesnt_match(list_of_terms)\n",
    "    list_of_terms.remove(word)\n",
    "    print(\"{:>10} not in {}\".format(word, str(list_of_terms)))\n",
    "\n",
    "terms = ['woman','movie','cats','nice','vacation']\n",
    "\n",
    "for t in terms:\n",
    "    print_similar(t)\n",
    "print()\n",
    "\n",
    "print_analogy(['actor','woman'], ['man'])\n",
    "print_analogy(['paris','germany'], ['france'])\n",
    "print()\n",
    "\n",
    "print_doesnt_match(\"breakfast cereal dinner lunch\")\n",
    "print_doesnt_match(\"bird dog cat town\")\n",
    "print_doesnt_match(\"paris berlin frankfurt singapore\")\n",
    "print_doesnt_match(\"man woman child boy girl\")\n",
    "print_doesnt_match(\"john peter fred anna\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader\n",
    "\n",
    "# get vectors for terms\n",
    "words = \"animal bird dog cat horse fish bee monkey turtle car town train city paris berlin frankfurt singapore man woman child boy girl breakfast cereal dinner lunch\".split()\n",
    "vectors = word_vectors[words]\n",
    "\n",
    "# apply a PCA to map to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(vectors)\n",
    "\n",
    "# create a scatter plot of the projection\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0]+0.05, result[i, 1]-0.05), fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence-transformers/all-MiniLM-L6-v2 [(model homepage)](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "- This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "- By default, input text longer than 256 word pieces is truncated. \n",
    "\n",
    "## sentence-transformers/all-mpnet-base-v2 [(model homepage)](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)\n",
    "\n",
    "- This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "- By default, input text longer than 384 word pieces is truncated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 256\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 6.7657e-02,  6.3496e-02,  4.8713e-02,  7.9305e-02,  3.7448e-02,\n",
      "          2.6528e-03,  3.9375e-02, -7.0985e-03,  5.9361e-02,  3.1537e-02,\n",
      "          6.0098e-02, -5.2905e-02,  4.0607e-02, -2.5931e-02,  2.9843e-02,\n",
      "          1.1269e-03,  7.3515e-02, -5.0382e-02, -1.2239e-01,  2.3703e-02,\n",
      "          2.9727e-02,  4.2477e-02,  2.5634e-02,  1.9952e-03, -5.6919e-02,\n",
      "         -2.7160e-02, -3.2904e-02,  6.6025e-02,  1.1901e-01, -4.5879e-02,\n",
      "         -7.2621e-02, -3.2584e-02,  5.2341e-02,  4.5055e-02,  8.2530e-03,\n",
      "          3.6702e-02, -1.3942e-02,  6.5392e-02, -2.6427e-02,  2.0638e-04,\n",
      "         -1.3664e-02, -3.6281e-02, -1.9504e-02, -2.8974e-02,  3.9427e-02,\n",
      "         -8.8409e-02,  2.6243e-03,  1.3671e-02,  4.8306e-02, -3.1157e-02,\n",
      "         -1.1733e-01, -5.1169e-02, -8.8529e-02, -2.1896e-02,  1.4299e-02,\n",
      "          4.4417e-02, -1.3482e-02,  7.4339e-02,  2.6638e-02, -1.9876e-02,\n",
      "          1.7919e-02, -1.0605e-02, -9.0426e-02,  2.1327e-02,  1.4120e-01,\n",
      "         -6.4718e-03, -1.4038e-03, -1.5361e-02, -8.7357e-02,  7.2217e-02,\n",
      "          2.0140e-02,  4.2559e-02, -3.4901e-02,  3.1954e-04, -8.0297e-02,\n",
      "         -3.2747e-02,  2.8527e-02, -5.1366e-02,  1.0939e-01,  8.1933e-02,\n",
      "         -9.8404e-02, -9.3410e-02, -1.5129e-02,  4.5125e-02,  4.9417e-02,\n",
      "         -2.5187e-02,  1.5708e-02, -1.2929e-01,  5.3189e-03,  4.0234e-03,\n",
      "         -2.3457e-02, -6.7298e-02,  2.9228e-02, -2.6085e-02,  1.3062e-02,\n",
      "         -3.1166e-02, -4.8271e-02, -5.5886e-02, -3.8751e-02,  1.2001e-01,\n",
      "         -1.0392e-02,  4.8971e-02,  5.5354e-02,  4.4936e-02, -4.0098e-03,\n",
      "         -1.0296e-01, -2.9297e-02, -5.8340e-02,  2.7047e-02, -2.2017e-02,\n",
      "         -7.2224e-02, -4.1387e-02, -1.9330e-02,  2.7333e-03,  2.7703e-04,\n",
      "         -9.6759e-02, -1.0057e-01, -1.4192e-02, -8.0789e-02,  4.5393e-02,\n",
      "          2.4504e-02,  5.9761e-02, -7.3819e-02,  1.1984e-02, -6.6340e-02,\n",
      "         -7.6904e-02,  3.8516e-02, -5.5936e-33,  2.8001e-02, -5.6078e-02,\n",
      "         -4.8660e-02,  2.1557e-02,  6.0198e-02, -4.8140e-02, -3.5025e-02,\n",
      "          1.9331e-02, -1.7515e-02, -3.8921e-02, -3.8106e-03, -1.7029e-02,\n",
      "          2.8210e-02,  1.2829e-02,  4.7160e-02,  6.2103e-02, -6.4359e-02,\n",
      "          1.2929e-01, -1.3123e-02,  5.2307e-02, -3.7368e-02,  2.8909e-02,\n",
      "         -1.6898e-02, -2.3733e-02, -3.3349e-02, -5.1676e-02,  1.5536e-02,\n",
      "          2.0880e-02, -1.2537e-02,  4.5958e-02,  3.7272e-02,  2.8057e-02,\n",
      "         -5.9001e-02, -1.1699e-02,  4.9218e-02,  4.7033e-02,  7.3549e-02,\n",
      "         -3.7053e-02,  3.9846e-03,  1.0641e-02, -1.6153e-04, -5.2717e-02,\n",
      "          2.7593e-02, -3.9292e-02,  8.4472e-02,  4.8686e-02, -4.8587e-03,\n",
      "          1.7995e-02, -4.2857e-02,  1.2338e-02,  6.3996e-03,  4.0482e-02,\n",
      "          1.4889e-02, -1.5394e-02,  7.6295e-02,  2.3704e-02,  4.4524e-02,\n",
      "          5.0820e-02, -2.3126e-03, -1.8874e-02, -1.2334e-02,  4.6600e-02,\n",
      "         -5.6344e-02,  6.2993e-02, -3.1554e-02,  3.2491e-02,  2.3467e-02,\n",
      "         -6.5544e-02,  2.0171e-02,  2.5708e-02, -1.2387e-02, -8.3649e-03,\n",
      "         -6.6438e-02,  9.4307e-02, -3.5709e-02, -3.4248e-02, -6.6635e-03,\n",
      "         -8.0153e-03, -3.0971e-02,  4.3301e-02, -8.2140e-03, -1.5080e-01,\n",
      "          3.0769e-02,  4.0072e-02, -3.7929e-02,  1.9321e-03,  4.0053e-02,\n",
      "         -8.7708e-02, -3.6849e-02,  8.5796e-03, -3.1925e-02, -1.2526e-02,\n",
      "          7.3554e-02,  1.3474e-03,  2.0592e-02,  2.7110e-33, -5.1858e-02,\n",
      "          5.7836e-02, -9.1898e-02,  3.9442e-02,  1.0558e-01, -1.9691e-02,\n",
      "          6.1840e-02, -7.6346e-02,  2.4088e-02,  9.4005e-02, -1.1654e-01,\n",
      "          3.7120e-02,  5.2243e-02, -3.9586e-03,  5.7221e-02,  5.3285e-03,\n",
      "          1.2402e-01,  1.3902e-02, -1.1025e-02,  3.5605e-02, -3.3075e-02,\n",
      "          8.1657e-02, -1.5200e-02,  6.0559e-02, -6.0140e-02,  3.2610e-02,\n",
      "         -3.4830e-02, -1.6988e-02, -9.7491e-02, -2.7148e-02,  1.7471e-03,\n",
      "         -7.6898e-02, -4.3186e-02, -1.8998e-02, -2.9166e-02,  5.7749e-02,\n",
      "          2.4182e-02, -1.1690e-02, -6.2143e-02,  2.8435e-02, -2.3746e-04,\n",
      "         -2.5178e-02,  4.3963e-03,  8.1284e-02,  3.6418e-02, -6.0401e-02,\n",
      "         -3.6552e-02, -7.9375e-02, -5.0852e-03,  6.6970e-02, -1.1778e-01,\n",
      "          3.2374e-02, -4.7125e-02, -1.3446e-02, -9.4845e-02,  8.2495e-03,\n",
      "         -1.0675e-02, -6.8188e-02,  1.1182e-03,  2.4802e-02, -6.3589e-02,\n",
      "          2.8449e-02, -2.6130e-02,  8.5811e-02,  1.1468e-01, -5.3535e-02,\n",
      "         -5.6359e-02,  4.2601e-02,  1.0945e-02,  2.0958e-02,  1.0013e-01,\n",
      "          3.2605e-02, -1.8421e-01, -3.9321e-02, -6.9145e-02, -6.3810e-02,\n",
      "         -6.5639e-02, -6.4125e-03, -4.7961e-02, -7.6813e-02,  2.9538e-02,\n",
      "         -2.2995e-02,  4.1704e-02, -2.5005e-02, -4.5451e-03, -4.1714e-02,\n",
      "         -1.3229e-02, -6.3836e-02, -2.4647e-03, -1.3734e-02,  1.6898e-02,\n",
      "         -6.3040e-02,  8.9888e-02,  4.1817e-02, -1.8569e-02, -1.8044e-08,\n",
      "         -1.6800e-02, -3.2158e-02,  6.3038e-02, -4.1309e-02,  4.4482e-02,\n",
      "          2.0247e-03,  6.2959e-02, -5.1737e-03, -1.0044e-02, -3.0564e-02,\n",
      "          3.5267e-02,  5.5858e-02, -4.6712e-02,  3.4510e-02,  3.2958e-02,\n",
      "          4.3011e-02,  2.9436e-02, -3.0316e-02, -1.7111e-02,  7.3748e-02,\n",
      "         -5.4791e-02,  2.7751e-02,  6.2017e-03,  1.5880e-02,  3.4298e-02,\n",
      "         -5.1575e-03,  2.3508e-02,  7.5314e-02,  1.9284e-02,  3.3620e-02,\n",
      "          5.0910e-02,  1.5250e-01,  1.6421e-02,  2.7053e-02,  3.7516e-02,\n",
      "          2.1855e-02,  5.6633e-02, -3.9575e-02,  7.1231e-02, -5.4138e-02,\n",
      "          1.0377e-03,  2.1185e-02, -3.5631e-02,  1.0902e-01,  2.7653e-03,\n",
      "          3.1400e-02,  1.3842e-03, -3.4574e-02, -4.5928e-02,  2.8808e-02,\n",
      "          7.1690e-03,  4.8468e-02,  2.6102e-02, -9.4407e-03,  2.8217e-02,\n",
      "          3.4872e-02,  3.6910e-02, -8.5895e-03, -3.5321e-02, -2.4786e-02,\n",
      "         -1.9192e-02,  3.8071e-02,  5.9965e-02, -4.2229e-02],\n",
      "        [ 8.6439e-02,  1.0276e-01,  5.3946e-03,  2.0445e-03, -9.9634e-03,\n",
      "          2.5386e-02,  4.9288e-02, -3.0627e-02,  6.8725e-02,  1.0137e-02,\n",
      "          7.7540e-02, -9.0081e-02,  6.1062e-03, -5.6990e-02,  1.4171e-02,\n",
      "          2.8049e-02, -8.6846e-02,  7.6440e-02, -1.0349e-01, -6.7744e-02,\n",
      "          6.9995e-02,  8.4425e-02, -7.2491e-03,  1.0477e-02,  1.3402e-02,\n",
      "          6.7758e-02, -9.4209e-02, -3.7169e-02,  5.2262e-02, -3.1085e-02,\n",
      "         -9.6341e-02,  1.5772e-02,  2.5787e-02,  7.8525e-02,  7.8995e-02,\n",
      "          1.9152e-02,  1.6436e-02,  3.1009e-03,  3.8131e-02,  2.3709e-02,\n",
      "          1.0539e-02, -4.4065e-02,  4.4174e-02, -2.5873e-02,  6.1538e-02,\n",
      "         -4.0543e-02, -8.6414e-02,  3.1972e-02, -8.9068e-04, -2.4444e-02,\n",
      "         -9.1972e-02,  2.3394e-02, -8.3029e-02,  4.4151e-02, -2.4969e-02,\n",
      "          6.2302e-02, -1.3035e-03,  7.5140e-02,  2.4638e-02, -6.4724e-02,\n",
      "         -1.1773e-01,  3.8339e-02, -9.1177e-02,  6.3545e-02,  7.6274e-02,\n",
      "         -8.8024e-02,  9.5456e-03, -4.6972e-02, -8.4174e-02,  3.8882e-02,\n",
      "         -1.1439e-01,  6.2886e-03, -3.4936e-02,  2.3975e-02, -3.3132e-02,\n",
      "         -1.5724e-02, -3.7896e-02, -8.8125e-03,  7.0612e-02,  3.2807e-02,\n",
      "          2.0367e-03, -1.1228e-01,  6.7972e-03,  1.2277e-02,  3.3530e-02,\n",
      "         -1.3620e-02, -2.2549e-02, -2.2523e-02, -2.0320e-02,  5.0430e-02,\n",
      "         -7.4865e-02, -8.2282e-02,  7.6596e-02,  4.9339e-02, -3.7555e-02,\n",
      "          1.4463e-02, -5.7246e-02, -1.7995e-02,  1.0970e-01,  1.1946e-01,\n",
      "          8.0923e-04,  6.1706e-02,  3.2632e-02, -1.3078e-01, -1.4864e-01,\n",
      "         -6.1623e-02,  4.3389e-02,  2.6713e-02,  1.3979e-02, -3.9400e-02,\n",
      "         -2.5271e-02,  3.8774e-03,  3.5866e-02, -6.1542e-02,  3.7666e-02,\n",
      "          2.6757e-02, -3.8266e-02, -3.5479e-02, -2.3923e-02,  8.6798e-02,\n",
      "         -1.8406e-02,  7.7104e-02,  1.3986e-03,  7.0038e-02, -4.7788e-02,\n",
      "         -7.8982e-02,  5.1081e-02, -2.9987e-33, -3.9165e-02, -2.5621e-03,\n",
      "          1.6521e-02,  9.4894e-03, -5.6622e-02,  6.5778e-02, -4.7700e-02,\n",
      "          1.1166e-02, -5.7356e-02, -9.1626e-03, -2.1752e-02, -5.5953e-02,\n",
      "         -1.1142e-02,  9.3279e-02,  1.6677e-02, -1.3672e-02,  4.3439e-02,\n",
      "          1.8724e-03,  7.2995e-03,  5.1633e-02,  4.8061e-02,  1.3534e-01,\n",
      "         -1.7174e-02, -1.2970e-02, -7.5011e-02,  2.6111e-02,  2.6980e-02,\n",
      "          7.8303e-04, -4.8727e-02,  1.1784e-02, -4.5958e-02, -4.8321e-02,\n",
      "         -1.9567e-02,  1.9389e-02,  1.9881e-02,  1.6743e-02,  9.8780e-02,\n",
      "         -2.7409e-02,  2.3481e-02,  3.7023e-03, -6.1451e-02, -1.2123e-03,\n",
      "         -9.5047e-03,  9.2515e-03,  2.3844e-02,  8.6123e-02,  2.2679e-02,\n",
      "          5.4512e-04,  3.4713e-02,  6.2546e-03, -6.9277e-03,  3.9240e-02,\n",
      "          1.1568e-02,  3.2628e-02,  6.2216e-02,  2.7611e-02,  1.8688e-02,\n",
      "          3.5581e-02,  4.1180e-02,  1.5478e-02,  4.2269e-02,  3.8225e-02,\n",
      "          1.0031e-02, -2.8325e-02,  4.4705e-02, -4.1046e-02, -4.5055e-03,\n",
      "         -5.4473e-02,  2.6232e-02,  1.7986e-02, -1.2312e-01, -4.6695e-02,\n",
      "         -1.3591e-02,  6.4671e-02,  3.5735e-03, -1.2223e-02, -1.7938e-02,\n",
      "         -2.5550e-02,  2.3722e-02,  4.0867e-03, -6.5148e-02,  4.4365e-02,\n",
      "          4.6860e-02, -3.2517e-02,  4.0227e-03, -3.9761e-03,  1.1194e-02,\n",
      "         -9.9560e-02,  3.3317e-02,  8.0106e-02,  9.4269e-02, -6.3829e-02,\n",
      "          3.2315e-02, -5.1355e-02, -7.4988e-03,  5.3005e-34, -4.1320e-02,\n",
      "          9.4965e-02, -1.0640e-01,  4.9659e-02, -3.4191e-02, -3.1675e-02,\n",
      "         -1.7156e-02,  1.7010e-03,  5.7976e-02, -1.2178e-03, -1.6854e-02,\n",
      "         -5.1691e-02,  5.5300e-02, -3.4265e-02,  3.0818e-02, -3.1048e-02,\n",
      "          9.2753e-02,  3.7266e-02, -2.3740e-02,  4.4589e-02,  1.4615e-02,\n",
      "          1.1624e-01, -5.0011e-02,  3.8872e-02,  4.2474e-03,  2.5698e-02,\n",
      "          3.2724e-02,  4.2991e-02, -1.3614e-02,  2.5612e-02,  1.0626e-02,\n",
      "         -8.4686e-02, -9.5298e-02,  1.0840e-01, -7.5160e-02, -1.3777e-02,\n",
      "          6.3734e-02, -4.4967e-03, -3.2532e-02,  6.2361e-02,  3.4805e-02,\n",
      "         -3.5492e-02, -2.0022e-02,  3.6661e-02, -2.4884e-02,  1.0182e-02,\n",
      "         -7.0123e-02, -4.3195e-02,  2.9533e-02, -2.9493e-04, -3.4539e-02,\n",
      "          1.4668e-02, -9.8397e-02, -4.7049e-02, -8.8550e-03, -8.8991e-02,\n",
      "          3.5100e-02, -1.2960e-01, -4.9887e-02, -6.1205e-02, -5.9780e-02,\n",
      "          9.4632e-03,  4.9122e-02, -7.7503e-02,  8.0973e-02, -4.7926e-02,\n",
      "          2.3438e-03,  7.5703e-02, -2.4018e-02, -1.5255e-02,  4.8674e-02,\n",
      "         -3.8597e-02, -7.0483e-02, -1.2035e-02, -3.8879e-02, -7.7602e-02,\n",
      "         -1.0724e-02,  1.0419e-02, -2.1375e-02, -9.1739e-02, -1.1134e-02,\n",
      "         -2.9607e-02,  2.4646e-02,  4.6571e-03, -1.6345e-02, -3.9522e-02,\n",
      "          7.7337e-02, -2.8473e-02, -3.6994e-03,  8.2767e-02, -1.1041e-02,\n",
      "          3.1398e-02,  5.3509e-02,  5.7515e-02, -3.1762e-02, -1.5291e-08,\n",
      "         -7.9966e-02, -4.7680e-02, -8.5979e-02,  5.6962e-02, -4.0887e-02,\n",
      "          2.2383e-02, -4.6445e-03, -3.8013e-02, -3.1067e-02, -1.0728e-02,\n",
      "          1.9770e-02,  7.7700e-03, -6.0948e-03, -3.8638e-02,  2.8027e-02,\n",
      "          6.7814e-02, -2.3535e-02,  3.2175e-02,  8.0254e-03, -2.3911e-02,\n",
      "         -1.2200e-03,  3.1460e-02, -5.2492e-02, -8.0682e-03,  3.1477e-03,\n",
      "          5.1150e-02, -4.4410e-02,  6.3601e-02,  3.8508e-02,  3.3043e-02,\n",
      "         -4.1873e-03,  4.9559e-02, -5.6961e-02, -6.4971e-03, -2.4979e-02,\n",
      "         -1.6087e-02,  6.6229e-02, -2.0631e-02,  1.0805e-01,  1.6855e-02,\n",
      "          1.4381e-02, -1.3213e-02, -1.2939e-01,  6.9522e-02, -5.5577e-02,\n",
      "         -6.7541e-02, -5.4582e-03, -6.1360e-03,  3.9084e-02, -6.2878e-02,\n",
      "          3.7406e-02, -1.1657e-02,  1.2915e-02, -5.5250e-02,  5.1608e-02,\n",
      "         -4.3084e-03,  5.8025e-02,  1.8695e-02,  2.2781e-02,  3.2167e-02,\n",
      "          5.3798e-02,  7.0285e-02,  7.4931e-02, -8.4177e-02]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "[ 0.01898636 -0.08441787 -1.0005357   0.15583566 -0.14950188  0.31966394\n",
      "  1.3621886   0.09708939  0.7396687  -0.0536701 ]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder, SentenceTransformer, util\n",
    "\n",
    "model_name = 'nq-distilbert-base-v1'\n",
    "bi_encoder = SentenceTransformer(model_name)\n",
    "\n",
    "# encode a sentence\n",
    "vector = bi_encoder.encode('This is a test sentence')\n",
    "print(len(vector))\n",
    "print(vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 509663 paragraphs\n"
     ]
    }
   ],
   "source": [
    "import os, gzip, json\n",
    "\n",
    "# As dataset, we use Simple English Wikipedia. Compared to the full English wikipedia, it has only\n",
    "# about 170k articles. We split these articles into paragraphs and encode them with the bi-encoder\n",
    "filepath = 'data/simplewiki-2020-11-01.jsonl.gz'\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    util.http_get('http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz', filepath)\n",
    "\n",
    "# extract all paragraphs\n",
    "paragraphs = []\n",
    "with gzip.open(filepath, 'rt', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        for i, p in enumerate(data['paragraphs']):\n",
    "            paragraphs.append({'title': data['title'], 'text': p, 'id': f\"{data['id']}:{i}\"})\n",
    "\n",
    "print(f'created {len(paragraphs)} paragraphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: min=21, max=6628, mean=250\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 paragraphs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Ted Cassidy',\n",
       "  'text': 'Ted Cassidy (July 31, 1932 - January 16, 1979) was an American actor. He was best known for his roles as Lurch and Thing on \"The Addams Family\".',\n",
       "  'id': '9822:0'},\n",
       " {'title': 'Aileen Wuornos',\n",
       "  'text': 'Aileen Carol Wuornos Pralle (born Aileen Carol Pittman; February 29, 1956\\xa0– October 9, 2002) was an American serial killer. She was born in Rochester, Michigan. She confessed to killing six men in Florida and was executed in Florida State Prison by lethal injection for the murders. Wuornos said that the men she killed had raped her or tried to rape her while she was working as a prostitute.',\n",
       "  'id': '9824:0'},\n",
       " {'title': 'Aileen Wuornos',\n",
       "  'text': 'Wuornos was diagnosed with antisocial personality disorder and borderline personality disorder.',\n",
       "  'id': '9824:1'},\n",
       " {'title': 'Aileen Wuornos',\n",
       "  'text': 'The movie, \"Monster\" is about her life. Two documentaries were made about her.',\n",
       "  'id': '9824:2'},\n",
       " {'title': 'Aileen Wuornos',\n",
       "  'text': 'Wuornos was born Aileen Carol Pittman in Rochester, Michigan. She never met her father. Wuornos was adopted by her grandparents. When she was 13 she became pregnant. She started working as a prostitute when she was 14.',\n",
       "  'id': '9824:3'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame([len(p['text']) for p in paragraphs], columns = ['length'])\n",
    "print(f'length: min={df.length.min():0.0f}, max={df.length.max():0.0f}, mean={df.length.mean():0.0f}')\n",
    "sns.displot(df, x='length', bins=500, height=3, aspect=5)\n",
    "plt.xlim(0, 2000)\n",
    "plt.show()\n",
    "\n",
    "print(f'first 5 paragraphs:')\n",
    "paragraphs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the encodings (unless we alread have them)\n",
    "filepath = f'data/simplewiki-2020-11-01-{model_name}.pt'\n",
    "\n",
    "if os.path.exists(filepath):\n",
    "    embeddings = torch.load(filepath)\n",
    "else:\n",
    "    # this can take a while\n",
    "    embeddings = bi_encoder.encode([p['title'] + ' ' + p['text'] for p in paragraphs], convert_to_tensor=True, show_progress_bar=True)\n",
    "    torch.save(embeddings, filepath)\n",
    "\n",
    "embeddings = embeddings.float()\n",
    "if torch.cuda.is_available():\n",
    "    embeddings = embeddings.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.004178143572062254,\n",
       "  'start': 19,\n",
       "  'end': 35,\n",
       "  'answer': 'she is the queen'},\n",
       " {'score': 9.64819491855451e-07, 'start': 10, 'end': 14, 'answer': 'king'},\n",
       " {'score': 1.44779889410529e-07,\n",
       "  'start': 0,\n",
       "  'end': 17,\n",
       "  'answer': 'Peter is the king'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "qa_model(question=[\"who is the queen\", \"who is the queen\", \"who is the queen\"], context=[\"I am the king, but she is the queen\", \"I was the king\", \"Peter is the king\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Apple iPhone\n",
      "\tbi-encoder\t0.553\t{'title': 'Apple Inc.', 'text': 'There are several different types of iPods:', 'id': '7111:4'}\n",
      "\tbi-encoder\t0.538\t{'title': 'Apple Inc.', 'text': 'The iPhone is a mobile phone that can make calls, send text messages, play games and music, show photos and videos (like an iPod), browse the Internet, and do much more. It was one of the first smartphones in the world when the first version was announced in 2007. Apple usually makes and sells a different model every year, with new models being faster and more powerful and having a newer version of iOS than those that come before them. The newest iPhones released are the iPhone 11 and the iPhone 11 Pro which run on iOS 13. Many cellular carriers around the world sell iPhones, including Sprint, Verizon, AT&T, and T-Mobile in the US.', 'id': '7111:10'}\n",
      "\tbi-encoder\t0.517\t{'title': 'Mac OS', 'text': '\"For the Apple computer family, see macOS\"', 'id': '516:0'}\n",
      "\tbi-encoder\t0.487\t{'title': 'IOS', 'text': 'iOS (previously named iPhone OS) is an operating system for mobile devices, made and sold by Apple Inc. It is the mobile operating system of the iPhone, the iPod Touch, the iPad, Apple TV and similar devices. iOS was originally called the iPhone OS but was renamed in 2010 to reflect the operating system’s evolving support for additional Apple devices.', 'id': '249777:0'}\n",
      "\tbi-encoder\t0.485\t{'title': 'Gangstar: West Coast Hustle', 'text': 'Gangstar: West Coast Hustle is a game for the iPhone.', 'id': '461587:0'}\n",
      "\tcross-encoder\t0.699\t{'title': 'Apple Inc.', 'text': 'Apple Inc. is a multinational company that makes computer hardware (the Macintoshes), software (macOS, iOS, watchOS and tvOS), and mobile devices (iPod, iPhone and iPad) like music players. Apple calls its computers \"Macintoshes\" or \"Macs\", and it calls its laptops \"MacBooks\". Their popular line of mobile music players is called \"iPod\", their smartphone line is called \"iPhone\" and their tablet line is called \"iPad\". Apple sells their products all around the world. Apple Inc. used to be called Apple Computer, Inc., but Apple changed their name after introducing the original iPhone.', 'id': '7111:0'}\n",
      "\tcross-encoder\t0.674\t{'title': 'IOS', 'text': 'iOS (previously named iPhone OS) is an operating system for mobile devices, made and sold by Apple Inc. It is the mobile operating system of the iPhone, the iPod Touch, the iPad, Apple TV and similar devices. iOS was originally called the iPhone OS but was renamed in 2010 to reflect the operating system’s evolving support for additional Apple devices.', 'id': '249777:0'}\n",
      "\tcross-encoder\t0.637\t{'title': 'Apple TV', 'text': 'Apple TV is a digital streaming device made by Apple Inc. Apple is a company that makes the iPhone, iPod, and iPad. There are 4 generations of the Apple TV. It can be used to stream content (for example, music, movies, TV shows, pictures etc.) from other Apple devices or iCloud to a TV.', 'id': '297077:0'}\n",
      "\tcross-encoder\t0.622\t{'title': 'Whipped cream', 'text': \"Whipped cream is used in many types of desserts. Some desserts, such as apple pie or strawberry shortcake, are often served with whipped cream on top. Whipped cream is also served in milk shakes, Alex's coffee, and on ice cream sundaes. Some desserts have whipped cream inside them, such as cream puffs and eclairs.\", 'id': '56515:2'}\n",
      "\tcross-encoder\t0.620\t{'title': 'Battery charger', 'text': 'Battery chargers can be found in many forms, such as for mobile phone batteries, an electric vehicle charger, and a laptop battery charger (adapter).', 'id': '427990:1'}\n",
      "\treader\t\t\tfourth generation;   fourth;   fourth generation iPad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4859 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttext2text-q\t\tApple iPhone - iPhone XS\n",
      "\ttext2text-p\t\tThe iPhone is a mobile phone that can make calls, send text messages, play games and music, show photos and videos (like an iPod), browse the Internet, and do much more.\n",
      "\tprompt\t\t\tSynthesize a comprehensive answer from the following context for the given question. Provide a clear and concise response that summarizes the key points and information presented in the text. Your answer should be in your own words and be no longer than 50 words. If you don't know the answer, then say so. Question: Apple iPhone Context: Apple Inc.: There are several different types of iPods: Apple Inc.: The iPhone is a mobile phone that can make calls, send text messages, play games and music, show photos and videos (like an iPod), browse the Internet, and do much more. It was one of the first smartphones in the world when the first version was announced in 2007. Apple usually makes and sells a different model every year, with new models being faster and more powerful and having a newer version of iOS than those that come before them. The newest iPhones released are the iPhone 11 and the iPhone 11 Pro which run on iOS 13. Many cellular carriers around the world sell iPhones, including Sprint, Verizon, AT&T, and T-Mobile in the US. Mac OS: \"For the Apple computer family, see macOS\" IOS: iOS (previously named iPhone OS) is an operating system for mobile devices, made and sold by Apple Inc. It is the mobile operating system of the iPhone, the iPod Touch, the iPad, Apple TV and similar devices. iOS was originally called the iPhone OS but was renamed in 2010 to reflect the operating system’s evolving support for additional Apple devices. Gangstar: West Coast Hustle: Gangstar: West Coast Hustle is a game for the iPhone. IPhone 11: The iPhone 11 is a smartphone sold by Apple Inc. It is replacing the iPhone X that was released in 2018. The iPhone 11 has two rear camera lenses but still has a 6.1-inch screen, like the X. It is available in purple, white, yellow, green, black, and PRODUCT(RED) finishes, with 64 GB, 128 GB, and 256 GB storage options. The starting price is US $699. It is the least expensive 2019 iPhone model, when compared to the iPhone 11 Pro and iPhone 11 Pro Max. IOS 6: iOS 6 is the sixth major version of Apple's mobile operating system, iOS. It was released on September 19, 2012. The newest version of iOS 6 is iOS 6.1.6. IPod: The most expensive iPod is called the iPod touch. It has a touch screen, like the iPhone. The first iPod touch was released in 2007. Samsung Galaxy Note: Samsung Galaxy Note is a series of smartphones and tablet computers made by Samsung Electronics. They use Android as their operating system. IPhone (1st generation): On June 9, 2008, Apple announced a version of the iPhone which featured slightly improved hardware, GPS, and 3G functionality. IPad (1st generation): The first generation iPad is a tablet computer that is design and sold by Apple Inc. It has an Apple A4 processor and a 9.7 inch touchscreen. It can play music, send and receive email, and browse the web. Apple: There are lots of different varieties of apples, including: IPhone 5: The iPhone 5 is a smartphone made by Apple. It is the sixth generation of the iPhone, the next smartphone after the iPhone 4S and before the iPhone 5S and iPhone 5C. It was revealed on September 12, 2012 and then released on September 21, 2012. IPhone 4: The iPhone 4 is a smartphone made by Apple. It was first released on June 24, 2010. It was the first iPhone to include a front-facing camera. IPhone: The iPhone is a series of smartphones made by Apple Inc since 2007. It does many things that a computer can do, but is small enough to fit in someone's hand. It is a mobile phone, meaning that it makes calls and sends text messages but without wires. There are many types of iPhones, such as the model iPhone X. IPhone: There have been ten types of iPhone models. IOS 5: iOS 5 is the fifth major version of Apple's mobile operating system, iOS. It came after iOS 4, and was replaced by iOS 6, which was released on September 19, 2012. The current version of iOS 5 is iOS 5.1.1. Super Mario: New Super Mario Bros. Wii American Staffordshire Terrier: The American Staffordshire terrier is a breed of dog. 24-hour clock: Many models of digital wristwatches and clocks are available that display the time of day using the 24-hour clock. Custard cream: A custard cream is a type of biscuit which is popular in the United Kingdom. It looks like a biscuit sandwich with a cream center. Apple Inc.: Apple is perhaps most famous for its mobile devices, which are small computers that are easy to carry around. They have touchscreens with multi-touch technology instead of a separate keyboard and mouse. Most of these products run an operating system called iOS. It is very similar to the Android software made by Google. iOS can do a lot of different things, and it does so by running \"apps\", which are programs similar to those on a PC. Users can download and buy more apps for their device from Apple's App Store. Blocked: Blocked is a puzzle game for the iPhone and iPod Touch. IOS 10: iOS 10 is a version of iOS released on September 13, 2016, preceded by iOS 9. iOS 10 includes new features such as 3D touch improvements, the lock screen, Emojis in Messages, Siri's compatibility to third-party apps, and many others. This is the first time Apple has dropped support for devices since iOS 8. Apple since then have a limited support for the iPhone 5, iPhone 5C, and the fourth-generation iPad. IPhone 4S: The iPhone 4S is the fifth iPhone that was created by Apple. It is very thin, and has a touchscreen. Apple Inc.: Apple is most well known for computers. Computers by Apple run the OS X operating system, which is included with every new Mac. Apple Inc.: The iPad is a tablet computer, similar to the iPhone and iPod Touch but with a much larger display - while a typical iPhone has a screen about 4 to 5 inches in size, iPads have screens from 8 to 12 inches big. The first iPad was introduced in 2010 and along with the iPhone, new and better models are made and sold every year. The newest iPads, the iPad Air and iPad Pro came out in 2015. They have new designs and features such as a front and back camera, true tone flash and a new 64-bit processor. They, too, ship with the latest IPad OS software if it is supported. IPhone: All iPhones run on a mobile operating system which Apple calls \"iOS\". A new version of iOS comes out every year, each having more features than the one before. Each new iPhone comes with the latest version of iOS, and older iPhones usually also get a software update to the latest version. The more-recent iPhones, such as the iPhone 11 and variants of it, use iOS 13 and came out in September 2019. Apple pie: An apple pie is a pie or tart filled with apples. Sometimes it has whipped cream or ice cream on top. It is a common type of pie. It is commonly associated with American culture, e.g. the expression 'As American as apple pie'. IPad: Apple re-entered the mobile device market in 2007 when the iPhone was released. Some of the iPhone's features are based on the Newton. Symbian: Symbian OS is an operating system for mobile devices. It is designed for smartphones. Long-tailed river stingray: The long-tailed river stingray or antenna ray, \"Plesiotrygon iwamae\", is a species of freshwater stingray in the family Potamotrygonidae. Wilhelm scream: In 2010, a Wilhelm Scream App was released on the Apple iPhone. As of 2011, it is still free to download. IPod Touch 6: The iPod Touch 6, is the sixth iPod Touch released by Apple Inc. It was first released on July 15, 2015. It is a handheld tablet computer. The iPod Touch 6 can do many things that iPhones can do except it cannot use cellular data (which is required for making calls or texting without WiFi). Critics praise the iPod Touch 6 as a low-cost device that produces good quality photos, though they criticize the iPod Touch 6 for having a poor battery life and a small screen. India: National fruit- mango IPad Air: The iPad Air can run iOS 12. It can act as a mobile hotspot, sharing its internet connection over Wifi, USB, or Bluetooth. It can have access to the App Store, where users can buy and download mobile applications onto their device. IPad (4th generation): The fourth generation iPad (sold as iPad with Retina display, sometimes called the iPad 4) is a tablet computer that is made and sold by Apple Inc. The fourth generation iPad kept the same Retina display as the last generation, but added some new features such as the Apple A6X chip, and the Lightning connector, which replaced the 30-pin dock connector. It was shipped with iOS 6, but can run the latest version of iOS, which is iOS 8. IPhone 12: The iPhone 12 is a smartphone made by Apple Inc. released on 13 October, 2020. Succeeding the iPhone 11, it has an identical 6.1-inch screen size to it's predecessor, but also comes in a smaller variant called the iPhone 12 mini. Both models have dual rear camera lenses, and come in storage options of 64 GB, 128 GB, and 256 GB. It is equipped with the Apple A14 Bionic System-on-Chip (SoC). The iPhone 12 mini starts at US $649, iPhone 12 starts at US $799 while the pro models (iPhone 12 pro & iPhone 12 pro max) cost US $1000 and US $1099 IOS 8: iOS 8 is the eighth major version of Apple's mobile operating system, iOS. It was announced at the company's Worldwide Developers Conference (WWDC) on June 2, 2014. It contains several new features, such as an app named Health, and a framework called HealthKit. IPad (4th generation): On January 29, 2013, Apple announced a 128 GB version of the 4th generation iPad. It went on sale on February 5, 2013. IPod Touch (5th generation): The fifth generation iPod Touch (sold as iPod touch, sometimes called the iPod Touch 5 or iPod Touch 5G) is a pocket computer that is designed and sold by Apple Inc. It replaces the fourth generation iPod Touch. Like the iPhone 5, it is a thinner and lighter that introduces a 4-inch screen. Other new features include 1080p video recording, panoramic pictures, an LED flash, an Apple A5 processor, and Siri. IPod Touch (5th generation): The fifth generation iPod Touch runs Apple's iOS mobile operating system. It shipped with iOS 6, which was released on September 19, 2012. It can play music, movies, television shows, eBooks, audiobooks, and podcasts. IPhone SE (1st generation): The iPhone SE, iPhone 6S, and iPhone 6S Plus were the last iPhones to feature the standard 3.5 mm headphone jack. Scaredy Squirrel (TV series): Scaredy Squirrel is a Canadian animated comedy television series. Japanese giant flying squirrel: The Japanese giant flying squirrel is a species of flying squirrel. IPod touch: The iPod touch is included with Wi-Fi 802.11b/g, and, like the iPhone, has the Safari web browser and YouTube. The iPod's Wi-Fi ability can also be used to buy music from the iTunes Store. Cross-platform: Microsoft Windows, macOS, iOS, BlackBerry, Linux and Android (operating system) are five different types of well-known platforms. Charlottetown: Charlottetown Stations IOS 11: On June 4, 2018, at the Worldwide Developers Conference, Apple announced its successor, iOS 12. IPhone 5S: The iPhone 5S is a smartphone that is designed and made by Apple Inc. It was released on September 20, 2013. Apple held an event to introduce the iPhone 5S, along with the iPhone 5C, on September 10, 2013. It has the same design as the iPhone 5, but has new features such as the Touch ID fingerprint scanner and an improved camera. Apple Inc.: Apple Inc. is a multinational company that makes computer hardware (the Macintoshes), software (macOS, iOS, watchOS and tvOS), and mobile devices (iPod, iPhone and iPad) like music players. Apple calls its computers \"Macintoshes\" or \"Macs\", and it calls its laptops \"MacBooks\". Their popular line of mobile music players is called \"iPod\", their smartphone line is called \"iPhone\" and their tablet line is called \"iPad\". Apple sells their products all around the world. Apple Inc. used to be called Apple Computer, Inc., but Apple changed their name after introducing the original iPhone. Valve: There are many types of valves. Some examples are: Wide-angle lens: One kind of wide-angle lens is a fish eye lens. IPod classic: The iPod Classic is a portable media player made by Apple Inc. To date, there have been six models of the iPod Classic, as well as the iPod Photo. All models use a 1.8-inch hard drive for storage. App Store (iOS): When the iPhone 5 was launched, Apple changed the look of the App Store, as well as the iTunes Store and iBookstore, as part of iOS 6. Lucky charms: Horseshoe Good Luck Charm. ... Squirrel: Squirrels are a large family of small to medium rodents. It includes tree squirrels, which are described on this page. Windows Phone: Windows Phone (formerly Windows Mobile) is a discontinued operating system from Microsoft for mobile phones. It is less popular than Android and iOS. IPhone (1st generation): The Original iPhone was the first phone made by Apple, Inc. It was announced in January 9, 2007, and released in June 29, 2007. It changed the mobile phone industry, being the first phone to include a capacitive Multi-touch display. It succeeded the Newton line of touch screen phones by Apple Computer, Inc. Crested Quetzal: The Crested Quetzal is a species of Quetzal. Lewis gun: The Lewis gun (or Lewis automatic machine gun or Lewis automatic rifle) is a First World War–era light machine gun. IOS 4: iOS 4 is the fourth version of the mobile software iOS, made by Apple Inc.. It was released on June 21, 2010. It was the first big change that was only called iOS, instead of iPhone OS. Some devices could not use iOS 4. This was also the first change that iPod Touch owners could have for free. Multi-touch: Today, multi-touch can be found on many electronic devices with touchscreens, such as smartphones, tablet computers, and even some PCs. Vaccination: There are different types of vaccines: IPhone 11 Pro: The iPhone 11 Pro and iPhone 11 Pro Max are smartphones sold by Apple Inc. They were released on September 20, 2019, as replacements to the iPhone X and X Max. The phones feature a third camera lens on the rear instead of two lenses. They are available in gold, silver, space gray, and a new midnight green shade. They ship with an 18-watt power adapter and a USB-C–to–Lightning cable for fast charging. IPadOS: iPadOS is a mobile operating system made by Apple Inc. for iPad tablet computers. It was released on September 24, 2019. It replaced iOS 12. Stroller: There are several different types of strollers: Samsung Galaxy: Besides their own products, Samsung also made the Nexus S and Galaxy Nexus phones, and the Nexus 10 tablet. These are all part of Google's own Nexus series of phones. Unlike Samsung's own phones, they have no extra mobile apps added or changes made to the user interface. Sandwich: There are many different types of sandwiches. Examples are: Bombinatoridae: Family Bombinatoridae IPad (4th generation): The fourth generation iPad shipped with iOS 6.1. It can act as a hotspot, meaning that it can share its internet connection over Wi-Fi, Bluetooth, or USB. It can also access the App Store, where users can buy and install applications for their device. FIFA 10: FIFA 10 (also known as FIFA Soccer 10 in North America) is video game in Electronic Arts' \"FIFA\" series of football video games. It was released for the PlayStation 3, Xbox 360, Windows, PlayStation 2, and Wii. CyanogenMod: CyanogenMod is an operating system for many smartphones and tablet computers. It is based on the Android operating system. This means all of Android's programs (called \"apps\") can be used with CyanogenMod. Whipped cream: Whipped cream is used in many types of desserts. Some desserts, such as apple pie or strawberry shortcake, are often served with whipped cream on top. Whipped cream is also served in milk shakes, Alex's coffee, and on ice cream sundaes. Some desserts have whipped cream inside them, such as cream puffs and eclairs. Wheelchair: A wheelchair is a type of chair usually used by disabled people. Cocktail: There are many kinds of cocktails. They include: Sidekick (TV series): Sidekick is a Canadian animated television comedy series. IOS 11: iOS 11 is the eleventh major release of the iOS mobile operating system developed by Apple Inc., coming after iOS 10. It was announced at the company's Worldwide Developers Conference on June 5, 2017, and released on September 19, 2017. Battery charger: Battery chargers can be found in many forms, such as for mobile phone batteries, an electric vehicle charger, and a laptop battery charger (adapter). Little Robots: Little Robots is a stop-motion animated children's television programme of BBC. IPad (3rd generation): The third generation iPad (sold as The new iPad, sometimes called the iPad 3) is a tablet computer that is made and sold by Apple Inc. It added new features, such as a Retina display, a new Apple A5X processor, a 5 megapixel camera, 1080p video recording, and support for LTE networks in North America. IPod classic: A 10GB iPod was released on March 20, 2002. United States Capitol dome: United States Capitol. Cane toad: The cane toad (\"Bufo marinus\") is a species of toad. They are also known as the giant neotropical toad and the marine toad. Asian emerald cuckoo: The Asian emerald cuckoo is a species of cuckoo in the Cuculidae family. Bear: Fictional bears include, Yogi Bear, Berenstain Bears, and Winnie the Pooh. Platypus (weevil): Platypus is a weevil genus in the subfamily Platypodinae. Passbook (application): Passbook is only officially provided by Apple for iOS. Several third party developers have created unsupported applications for other operating systems, such as PassWallet for Android, that support importing and viewing Passbook passes. IOS 6: iOS 6 was shown during Apple Worldwide Developers Conference (WWDC) 2012 on June 11, 2012. This software dropped support for older devices such as the third generation iPod Touch and the first generation iPad following the cycle of past iOS versions. It is supported on the iPhone 3GS and later, the fourth generation iPod Touch and later, the iPad 2 and later, and the iPad Mini. Apple strudel: Apple strudel () is a traditional Austrian dessert. It is also known in most of the countries which formed the Austro-Hungarian Empire. Apple TV: Apple TV is a digital streaming device made by Apple Inc. Apple is a company that makes the iPhone, iPod, and iPad. There are 4 generations of the Apple TV. It can be used to stream content (for example, music, movies, TV shows, pictures etc.) from other Apple devices or iCloud to a TV. Apple Inc.: One of the most popular products made by Apple is the iPod. It was first sold in 2001, and Apple sold over 100 million in six years. All iPods can play music with good quality. Recent iPod Touches have a high quality LED screens, can take and show good pictures, record, view and edit high definition videos, use the Internet for features such as e-mail, gaming, and blogging, record word and voice memos, and even get office work done. The latest iPod Touch is even made with a 64-bit architecture. Paisley (design): For example \"a paisley silk tie\" IPad Mini 4: The fourth-generation iPad Mini 4 (stylized and marketed as iPad mini 4) is a tablet computer that is made and sold by Apple Inc. It was first released on September 9, 2015. IPod touch: The specifications as listed on Apple's website are: Anguidae: Anguidae is a family of lizards. Light bulb: There are several kinds of light bulbs: IPod Touch (5th generation): The fifth generation iPod Touch also comes in several different colors: space grey, silver, pink, yellow, blue, and Product Red. The fifth generation iPod Touch was announced along with the iPhone 5 on September 12, 2012, and it was released on October 11, 2012. IOS 5: iOS 5 was announced during Apple's Worldwide Developers Conference (WWDC) 2011. Support was dropped for the iPhone 3G and the iPod Touch (2nd generation), and devices that are supported are the iPhone 3GS and later, the iPod Touch (3rd generation) and later, and the first generation iPad and later. Enterprise Java Beans: There are different kinds of Beans:\n",
      "\n",
      "\n",
      "========\n",
      "\n",
      "Query: Which product is better: iPhone or Samsung?When is the flight from Zurich to London?\n",
      "\tbi-encoder\t0.447\t{'title': 'London City Airport', 'text': 'The airport serves European destinations, though there is one flight to New York JFK airport.', 'id': '113000:1'}\n",
      "\tbi-encoder\t0.446\t{'title': 'Stratford station', 'text': 'Despite Stratford International\\'s name, no international trains call there, and Eurostar (currently the only international operator) has no plans to do so. Passengers instead interconnect on high-speed trains travelling to either London St Pancras or Ebbsfleet in Kent, there are a number of other potential operators that may use the station for international services. These include Deutsche Bahn\\'s proposed London-Frankfurt/Amsterdam service and the proposed \"Transmanche Metro\" service to Calais via local stations.', 'id': '181480:10'}\n",
      "\tbi-encoder\t0.436\t{'title': 'Munich', 'text': \"Lufthansa has opened a second hub at Munich's Franz Josef Strauss International Airport. It is the second-largest airport in Germany, after Frankfurt International Airport.\", 'id': '2917:5'}\n",
      "\tbi-encoder\t0.422\t{'title': 'Lille', 'text': 'There are two big railway stations in Lille with many trains to and from different places around France and Belgium. Most of these serve station and are operated by SNCF, including the TGV high-speed service. The other big station, , has Eurostar trains to and from Brussels, Paris, and St Pancras station in London via the Channel Tunnel to the United Kingdom.', 'id': '33943:2'}\n",
      "\tbi-encoder\t0.418\t{'title': 'Bamberg', 'text': 'Most international tourists who travel by plane arrive at Frankfurt International Airport or Munich Airport. The nearest bigger airport is Nuremberg Airport which can be reached within half an hour by car or one hour by train.', 'id': '37383:18'}\n",
      "\tcross-encoder\t0.498\t{'title': 'Dresden', 'text': 'Dresden has got an international airport \"(Flughafen Dresden-Klotzsche)\" which has about 2 million passengers/year. This Airport has got daily flight connections to Frankfurt and Munich (Lufthansa), Moscow (Aeroflot), Cologne and Stuttgart (germanwings), Düsseldorf (germanwings) as well as to Zurich (InterSky), Hamburg (eurowings on behalf of germanwings) and London-City (CityJet). The biggest station is \"Dresden Hauptbahnhof\" (Dresden Main station) with an ICE (InterCityExpress) connection to Leipzig, Erfurt, Frankfurt and Wiesbaden. There\\'s an EuroCity connection to Prague, Graz and Vienna just as an InterCity connection to Berlin and Hamburg. The metropolitan of Dresden has got four highwas:', 'id': '8524:6'}\n",
      "\tcross-encoder\t0.447\t{'title': 'Loop AI Labs', 'text': \"On May 4, 2017, Loop AI Labs entered into a deal with , a leading European provider of mobile messaging and solutions, to bring their cognitive computing technology to LINK's business clients, which cover 234 million people across Europe.\", 'id': '669662:1'}\n",
      "\tcross-encoder\t0.437\t{'title': 'Maastricht', 'text': 'The city can easily be reached. There is a highway (A2; E25) running from the south to the north (within the Netherlands, this highway runs from Eijsden to Amsterdam). Another highway also begins in Maastricht, the A79 (going to the east). Maastricht has two train stations (\"Maastricht\" and \"Maastricht Randwyck\"). Trains are going to Amsterdam, Heerlen, Roermond, and Brussels (B). Plans are made to re-establish the old train route to Lanaken (B). If this connections is to be made again, Maastricht will be accessible from all directions by train.', 'id': '32677:9'}\n",
      "\tcross-encoder\t0.416\t{'title': 'EuroAirport Basel Mulhouse Freiburg', 'text': 'EuroAirport Basel Mulhouse Freiburg is an international airport northwest of the city of Basel, Switzerland, southeast of Mulhouse in France, and south-southwest of Freiburg im Breisgau in Germany. It is in France in Saint-Louis near the Swiss and German borders. The airport is an hub for easyJet Switzerland with mainly flights to European metropolitan and leisure destinations. In 2018, the airport had 8,578,064 passengers.', 'id': '715638:0'}\n",
      "\tcross-encoder\t0.409\t{'title': 'Canton of Zürich', 'text': 'Zürich is a canton of Switzerland. About 1.2 million people live there. The canton is in the northeast of Switzerland. The city of Zürich is its capital. The official language is German, but people speak the local Swiss German dialect called \"Züritüütsch\". English writers often write the name of the Canton of Zürich as Canton of Zurich.', 'id': '92119:0'}\n",
      "\treader\t\t\tSamsung Galaxy;   Samsung () and Windows Phone;   Samsung\n",
      "\ttext2text-q\t\tApril 15, 2018\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\home\\work\\mmir-unibasel\\chapter04\\embeddings.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir-unibasel/chapter04/embeddings.ipynb#X42sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mtext2text-q\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mtext[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir-unibasel/chapter04/embeddings.ipynb#X42sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m prompt \u001b[39m=\u001b[39m create_prompt(queries[i], context)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/home/work/mmir-unibasel/chapter04/embeddings.ipynb#X42sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m text \u001b[39m=\u001b[39m answer_generator(prompt, max_length\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir-unibasel/chapter04/embeddings.ipynb#X42sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mtext2text-p\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00mtext[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/home/work/mmir-unibasel/chapter04/embeddings.ipynb#X42sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mprompt\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m prompt)\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:165\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    167\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[0;32m    168\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[0;32m    169\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[0;32m    170\u001b[0m     ):\n\u001b[0;32m    171\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\pipelines\\base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[0;32m   1133\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[0;32m   1134\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         )\n\u001b[0;32m   1138\u001b[0m     )\n\u001b[0;32m   1139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\pipelines\\base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1146\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1147\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1148\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1149\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\pipelines\\base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1045\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1046\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1047\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1048\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:187\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[0;32m    186\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 187\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    188\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\generation\\utils.py:1492\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m   1485\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1486\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgeneration results, please set `padding_side=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m\u001b[39m` when initializing the tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1487\u001b[0m         )\n\u001b[0;32m   1489\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[0;32m   1490\u001b[0m     \u001b[39m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[0;32m   1491\u001b[0m     \u001b[39m# and added to `model_kwargs`\u001b[39;00m\n\u001b[1;32m-> 1492\u001b[0m     model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m   1493\u001b[0m         inputs_tensor, model_kwargs, model_input_name\n\u001b[0;32m   1494\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m \u001b[39m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\generation\\utils.py:661\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    659\u001b[0m encoder_kwargs[\u001b[39m\"\u001b[39m\u001b[39mreturn_dict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    660\u001b[0m encoder_kwargs[model_input_name] \u001b[39m=\u001b[39m inputs_tensor\n\u001b[1;32m--> 661\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m]: ModelOutput \u001b[39m=\u001b[39m encoder(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    663\u001b[0m \u001b[39mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1123\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[0;32m   1111\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m   1112\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     )\n\u001b[0;32m   1122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m   1124\u001b[0m         hidden_states,\n\u001b[0;32m   1125\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1126\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m   1127\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1128\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1129\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[0;32m   1130\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m   1131\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[0;32m   1132\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m   1133\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1134\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1135\u001b[0m     )\n\u001b[0;32m   1137\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:695\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[0;32m    696\u001b[0m     hidden_states,\n\u001b[0;32m    697\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    698\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    699\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    700\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    701\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    702\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    703\u001b[0m )\n\u001b[0;32m    704\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[0;32m    705\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:602\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    592\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    593\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    599\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    600\u001b[0m ):\n\u001b[0;32m    601\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 602\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[0;32m    603\u001b[0m         normed_hidden_states,\n\u001b[0;32m    604\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    605\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    606\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    607\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m    608\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    609\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[0;32m    612\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:562\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    559\u001b[0m     position_bias_masked \u001b[39m=\u001b[39m position_bias\n\u001b[0;32m    561\u001b[0m scores \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_bias_masked\n\u001b[1;32m--> 562\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(scores\u001b[39m.\u001b[39;49mfloat(), dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtype_as(\n\u001b[0;32m    563\u001b[0m     scores\n\u001b[0;32m    564\u001b[0m )  \u001b[39m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[0;32m    565\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(\n\u001b[0;32m    566\u001b[0m     attn_weights, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining\n\u001b[0;32m    567\u001b[0m )  \u001b[39m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[39m# Mask heads if we want to\u001b[39;00m\n",
      "File \u001b[1;32mc:\\env\\bin\\python3\\lib\\site-packages\\torch\\nn\\functional.py:1843\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1842\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def text_from_hit(hit):\n",
    "    p = paragraphs[hit['corpus_id']]\n",
    "    return p['title']+': '+p['text']\n",
    "\n",
    "def create_prompt(query, context):\n",
    "    return \" \".join([\n",
    "        \"Synthesize a comprehensive answer from the following context for the given question.\",\n",
    "        \"Provide a clear and concise response that summarizes the key points and information presented in the text.\",\n",
    "        \"Your answer should be in your own words and be no longer than 50 words.\",\n",
    "        \"If you don't know the answer, then say so.\",\n",
    "        \"Question: \" + query,\n",
    "        \"Context: \" + context\n",
    "    ])\n",
    "\n",
    "\n",
    "# perform semantic search\n",
    "queries = [\n",
    "    \"Apple iPhone\",\n",
    "    \"Which product is better: iPhone or Samsung?\"\n",
    "    \"When is the flight from Zurich to London?\",\n",
    "    \"For what did Albert Einstein win the Nobelprize?\", \n",
    "    \"What is the Capital of France?\", \n",
    "    \"Who invented the iPhone?\", \n",
    "    \"What does Rhodes Statue look like?\", \n",
    "    \"Who won the FIFA World Cup 2018?\", \n",
    "    \"Who were the members of the Beatles band?\", \n",
    "    \"Who was Gandhi?\", \n",
    "    \"What does relativity mean?\"\n",
    "]\n",
    "q_vectors = bi_encoder.encode(queries, convert_to_tensor=True)\n",
    "hits = util.semantic_search(q_vectors, embeddings, top_k=100)\n",
    "\n",
    "# use this model for cross-encoder re-ranking\n",
    "model = CrossEncoder('cross-encoder/stsb-distilroberta-base')\n",
    "\n",
    "# use this model to provide answers\n",
    "qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# uset his model to generate a textual answer\n",
    "answer_generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    # print query\n",
    "    print(f\"Query: {queries[i]}\")\n",
    "    # print bi-encoder results\n",
    "    for hit in hits[i][0:5]:\n",
    "        print(f\"\\tbi-encoder\\t{hit['score']:.3f}\\t{paragraphs[hit['corpus_id']]}\")\n",
    "    # re-rank with cross-encoder\n",
    "    combinations = [[queries[i], text_from_hit(hit)] for hit in hits[i]]\n",
    "    cross_scores = model.predict(combinations)\n",
    "    # get indexes of top-k results\n",
    "    for j in cross_scores.argsort()[-5:][::-1]:\n",
    "        print(f\"\\tcross-encoder\\t{cross_scores[j]:.3f}\\t{paragraphs[hits[i][j]['corpus_id']]}\")\n",
    "    # build context from retrieved paragraphs\n",
    "    context = \" \".join([text_from_hit(hit) for hit in hits[i]])\n",
    "    ans = qa_model(question=queries[i], context=context, top_k=3)\n",
    "    answers = \";   \".join([a['answer'] for a in ans])\n",
    "    print(f\"\\treader\\t\\t\\t{answers}\")\n",
    "    # generate textual answer\n",
    "    text = answer_generator(queries[i], max_length=100)\n",
    "    print(f\"\\ttext2text-q\\t\\t{text[0]['generated_text']}\")\n",
    "    prompt = create_prompt(queries[i], context)\n",
    "    text = answer_generator(prompt, max_length=100)\n",
    "    print(f\"\\ttext2text-p\\t\\t{text[0]['generated_text']}\")\n",
    "    print(\"\\tprompt\\t\\t\\t\" + prompt)\n",
    "    print(\"\\n\\n========\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "tokens = nlp(\"this is a sentence. this is another sentence.\")\n",
    "tokens.vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
